{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2c - Topic Modeling LDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "from pprint import pprint\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('Sports_and_Outdoors_5.json',lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden der Pickle Datei mit dem POC-Datensatz auf den bereits Data Cleaning betrieben wurde\n",
    "#df_poc = pd.read_pickle('poc.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling - LDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei der Latent Direchlet Allocation handelt es sich um einen Algoeithmus zum Topic Modeling. Dafür wird angenommen, dass jedes Dokument aus einer Mischung von verschiedenen Themen besteht, jedes mit entsprechender Gewichtung. Jedes Wort in einem Dokument wird einen Thema zugeordnet.\n",
    "Damit besteht ein Thema aus einer Mischung aus Wörtern, ebenfalls mit entsprechender Gewichtung.\n",
    "\n",
    "Ein Wort kann dabei in mehreren Themen auftauchen, da es sich immer um eine Wahrscheinlichkeit des Auftauchen eines Wortes handelt.\n",
    "\n",
    "Es werden also die Verteilung von Wort-Thema und Thema-Dokument berechnet und diese werden genutzt um latente, vorhandene aber noch nicht sichtbare, Themen in einen Dokument zu finden."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POC - Beispieldatensatz "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für das erste Modell wird nur 1% des Datensatzes genutzt um die Funktionalität der Pipeline zu prüfen. Dies entspricht 28399 Reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28399, 5)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Für Testzwecke werden nur 1% des Datensatzes betrachtet: 28399 Zeilen\n",
    "df_poc = df.sample(frac=0.01, replace=False, random_state=1)\n",
    "df_poc = df_poc[['reviewerID', 'unixReviewTime' ,'asin', 'overall', 'reviewText']]\n",
    "df_poc.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Um die Daten später in ein LDA Model anwenden zu können, müssen diese entsprechen gesäubert und transformiert werden:\n",
    "- Text wird kleingeschrieben\n",
    "- Sonderzeichen werden entfernt\n",
    "- Text wird Tokenized (jedes Wort wird ein Element in einer Liste)\n",
    "- Stopwörte entfernen\n",
    "- Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df):\n",
    "\n",
    "    # Text kleinschreiben\n",
    "    df['reviewText'] = df['reviewText'].astype(str).str.lower()\n",
    "\n",
    "    # Textzeichen entfernen\n",
    "    df['reviewText'] = df['reviewText'].map(lambda x: re.sub(r'[,\\.!?]','', x))\n",
    "\n",
    "    # Tokenizen\n",
    "    regexp = RegexpTokenizer(r'\\w+')\n",
    "    df['reviewText_tokenize']=df['reviewText'].apply(regexp.tokenize)  \n",
    "    \n",
    "    # Stopwörter entfernen \n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    df['reviewText_tokenize'] = df['reviewText_tokenize'].apply(lambda x: [i for i in x if i not in stopwords])\n",
    "\n",
    "    # Lemmatization\n",
    "    lemma_list = []\n",
    "    lem = WordNetLemmatizer()\n",
    "\n",
    "    for row in df['reviewText_tokenize']:\n",
    "        holder = []\n",
    "        for elem in row:\n",
    "            holder.append(lem.lemmatize(elem, \"v\"))\n",
    "        lemma_list.append(holder)\n",
    "\n",
    "    df['reviewText_tokenize'] = lemma_list\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach dem Data Cleaning wird die neue Spalte 'reviewText_tokenize' erstellt, welche die gesäuberten Wörter in einer Liste abspeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewText_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1195218</th>\n",
       "      <td>A36JK2BSXS0U43</td>\n",
       "      <td>1517788800</td>\n",
       "      <td>B005NATM06</td>\n",
       "      <td>5</td>\n",
       "      <td>we are reviewing several sets of darts from vi...</td>\n",
       "      <td>[review, several, set, dart, viper, learn, gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138622</th>\n",
       "      <td>A374H5DSRDUT1P</td>\n",
       "      <td>1408147200</td>\n",
       "      <td>B000F7VV42</td>\n",
       "      <td>5</td>\n",
       "      <td>perfect</td>\n",
       "      <td>[perfect]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45540</th>\n",
       "      <td>AU52E1PVI59D0</td>\n",
       "      <td>1462060800</td>\n",
       "      <td>B00070QEN0</td>\n",
       "      <td>2</td>\n",
       "      <td>just lost another one - again  would someone p...</td>\n",
       "      <td>[lose, another, one, would, someone, please, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893937</th>\n",
       "      <td>A2TM7I63LF51L1</td>\n",
       "      <td>1487289600</td>\n",
       "      <td>B00M8MLSJ0</td>\n",
       "      <td>5</td>\n",
       "      <td>works good</td>\n",
       "      <td>[work, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914910</th>\n",
       "      <td>AXCRLIMPYXWUG</td>\n",
       "      <td>1467072000</td>\n",
       "      <td>B00MX89O2C</td>\n",
       "      <td>3</td>\n",
       "      <td>i got this lock because its a small size so it...</td>\n",
       "      <td>[get, lock, small, size, lighter, use, want, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             reviewerID  unixReviewTime        asin  overall  \\\n",
       "1195218  A36JK2BSXS0U43      1517788800  B005NATM06        5   \n",
       "138622   A374H5DSRDUT1P      1408147200  B000F7VV42        5   \n",
       "45540     AU52E1PVI59D0      1462060800  B00070QEN0        2   \n",
       "1893937  A2TM7I63LF51L1      1487289600  B00M8MLSJ0        5   \n",
       "1914910   AXCRLIMPYXWUG      1467072000  B00MX89O2C        3   \n",
       "\n",
       "                                                reviewText  \\\n",
       "1195218  we are reviewing several sets of darts from vi...   \n",
       "138622                                             perfect   \n",
       "45540    just lost another one - again  would someone p...   \n",
       "1893937                                         works good   \n",
       "1914910  i got this lock because its a small size so it...   \n",
       "\n",
       "                                       reviewText_tokenize  \n",
       "1195218  [review, several, set, dart, viper, learn, gam...  \n",
       "138622                                           [perfect]  \n",
       "45540    [lose, another, one, would, someone, please, m...  \n",
       "1893937                                       [work, good]  \n",
       "1914910  [get, lock, small, size, lighter, use, want, l...  "
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(df_poc)\n",
    "df_poc.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für das spätere Topic Modeling könnte es interessant sein, nur die Substative, Verben oder Adjektive von einem Text zu betrachten. Dafür wird das Natural Language Toolkit NLTK genutzt, welches Funktionen anbietet um für jedes Wort sein 'Part of Speech' zu erkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjectives(text):\n",
    "    pos = nltk.pos_tag(text)\n",
    "    adj = []\n",
    "    for elem in pos:\n",
    "        # print(elem)\n",
    "        if elem[1] not in ['NN', 'NNS', 'NNP', 'NNPS', 'VBZ', 'VBP', 'VBN', 'VBG', 'VBD', 'VB']:\n",
    "            adj.append(elem[0])\n",
    "    # print()\n",
    "    return adj\n",
    "\n",
    "def get_nouns(text):\n",
    "    pos = nltk.pos_tag(text)\n",
    "    noun = []\n",
    "    for elem in pos:\n",
    "        # print(elem)\n",
    "        if elem[1] in ['NN', 'NNS', 'NNP', 'NNPS']:\n",
    "            noun.append(elem[0])\n",
    "    # print()\n",
    "    return noun\n",
    "\n",
    "def get_verbs(text):\n",
    "    pos = nltk.pos_tag(text)\n",
    "    ver = []\n",
    "    for elem in pos:\n",
    "        # print(elem)\n",
    "        if elem[1] in ['VBZ', 'VBP', 'VBN', 'VBG', 'VBD', 'VB']:\n",
    "            ver.append(elem[0])\n",
    "    # print()\n",
    "    return ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poc['adjectives'] = df_poc['reviewText_tokenize'].apply(get_adjectives)\n",
    "df_poc['nouns'] = df_poc['reviewText_tokenize'].apply(get_nouns)\n",
    "df_poc['verbs'] = df_poc['reviewText_tokenize'].apply(get_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abspeichern der Ergebnisse nach dem Cleaning\n",
    "# df_poc.to_pickle('poc.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nochmal ein Blick auf den fertig aufbereiteten Datensatz. Die neuen Spalten sind:\n",
    "- reviewText_tokenize - Schlüsselwörter von reviewText als Liste\n",
    "- adjectives - nur Adjektive von reviewText als Liste\n",
    "- nouns - nur Substantive von reviewText als Liste\n",
    "- verbs - nur Verben von reviewText als Liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewText_tokenize</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1195218</th>\n",
       "      <td>A36JK2BSXS0U43</td>\n",
       "      <td>1517788800</td>\n",
       "      <td>B005NATM06</td>\n",
       "      <td>5</td>\n",
       "      <td>we are reviewing several sets of darts from vi...</td>\n",
       "      <td>[review, several, set, dart, viper, learn, gam...</td>\n",
       "      <td>[several, dart, non, pro, tip, awkward, comfor...</td>\n",
       "      <td>[viper, learn, game, husband, use, play, leagu...</td>\n",
       "      <td>[review, set, hold, say, want]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138622</th>\n",
       "      <td>A374H5DSRDUT1P</td>\n",
       "      <td>1408147200</td>\n",
       "      <td>B000F7VV42</td>\n",
       "      <td>5</td>\n",
       "      <td>perfect</td>\n",
       "      <td>[perfect]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[perfect]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45540</th>\n",
       "      <td>AU52E1PVI59D0</td>\n",
       "      <td>1462060800</td>\n",
       "      <td>B00070QEN0</td>\n",
       "      <td>2</td>\n",
       "      <td>just lost another one - again  would someone p...</td>\n",
       "      <td>[lose, another, one, would, someone, please, m...</td>\n",
       "      <td>[another, would, lanyard, buoyant, around, sin...</td>\n",
       "      <td>[one, someone, material, wire, work, clip, use...</td>\n",
       "      <td>[lose, please, make, make, cheapest]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893937</th>\n",
       "      <td>A2TM7I63LF51L1</td>\n",
       "      <td>1487289600</td>\n",
       "      <td>B00M8MLSJ0</td>\n",
       "      <td>5</td>\n",
       "      <td>works good</td>\n",
       "      <td>[work, good]</td>\n",
       "      <td>[good]</td>\n",
       "      <td>[work]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914910</th>\n",
       "      <td>AXCRLIMPYXWUG</td>\n",
       "      <td>1467072000</td>\n",
       "      <td>B00MX89O2C</td>\n",
       "      <td>3</td>\n",
       "      <td>i got this lock because its a small size so it...</td>\n",
       "      <td>[get, lock, small, size, lighter, use, want, l...</td>\n",
       "      <td>[lock, small, bike, forever, lock, one, right,...</td>\n",
       "      <td>[size, lighter, use, lock, frame, rack, work, ...</td>\n",
       "      <td>[get, want, take, get, go, find]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             reviewerID  unixReviewTime        asin  overall  \\\n",
       "1195218  A36JK2BSXS0U43      1517788800  B005NATM06        5   \n",
       "138622   A374H5DSRDUT1P      1408147200  B000F7VV42        5   \n",
       "45540     AU52E1PVI59D0      1462060800  B00070QEN0        2   \n",
       "1893937  A2TM7I63LF51L1      1487289600  B00M8MLSJ0        5   \n",
       "1914910   AXCRLIMPYXWUG      1467072000  B00MX89O2C        3   \n",
       "\n",
       "                                                reviewText  \\\n",
       "1195218  we are reviewing several sets of darts from vi...   \n",
       "138622                                             perfect   \n",
       "45540    just lost another one - again  would someone p...   \n",
       "1893937                                         works good   \n",
       "1914910  i got this lock because its a small size so it...   \n",
       "\n",
       "                                       reviewText_tokenize  \\\n",
       "1195218  [review, several, set, dart, viper, learn, gam...   \n",
       "138622                                           [perfect]   \n",
       "45540    [lose, another, one, would, someone, please, m...   \n",
       "1893937                                       [work, good]   \n",
       "1914910  [get, lock, small, size, lighter, use, want, l...   \n",
       "\n",
       "                                                adjectives  \\\n",
       "1195218  [several, dart, non, pro, tip, awkward, comfor...   \n",
       "138622                                                  []   \n",
       "45540    [another, would, lanyard, buoyant, around, sin...   \n",
       "1893937                                             [good]   \n",
       "1914910  [lock, small, bike, forever, lock, one, right,...   \n",
       "\n",
       "                                                     nouns  \\\n",
       "1195218  [viper, learn, game, husband, use, play, leagu...   \n",
       "138622                                           [perfect]   \n",
       "45540    [one, someone, material, wire, work, clip, use...   \n",
       "1893937                                             [work]   \n",
       "1914910  [size, lighter, use, lock, frame, rack, work, ...   \n",
       "\n",
       "                                        verbs  \n",
       "1195218        [review, set, hold, say, want]  \n",
       "138622                                     []  \n",
       "45540    [lose, please, make, make, cheapest]  \n",
       "1893937                                    []  \n",
       "1914910      [get, want, take, get, go, find]  "
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poc.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training des Models - LatentDirichletAllocation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für dieses Modell wird für jedes Dokument als Input ein String benötigt anstatt einer Liste von Wörtern. Deswegen wird in 'reviewText_cleaned' die Liste als String abgespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token2string(tokens):\n",
    "    erg = \" \".join(tokens)\n",
    "    return erg\n",
    "df_poc['reviewText_cleaned'] = df_poc['reviewText_tokenize'].apply(token2string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tfidf - Term Frequency Inverse Document Frequency: vergleicht die Häufigkeit an Wörtern mit der Anzahl an Dokumenten, welche das Wort enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "vect_text=vect.fit_transform(df_poc['reviewText_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components=5, learning_method='online', random_state=1) \n",
    "lda_top = lda_model.fit_transform(vect_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . Reviewtext:  we are reviewing several sets of darts from viper  i am just learning the game and my husband used to play in a non-pro league  the blitz steel tips are awkward for me to hold comfortably because they are so streamlined but to him these are now his new favorites  he says they do exactly what he wants he loves the weight and slimness that viper has created here these are \"serious\" darts for the more advanced player\n",
      "Thema  0 :  26.42497808561349 %\n",
      "Thema  1 :  3.2765930434143766 %\n",
      "Thema  2 :  3.3364007631194093 %\n",
      "Thema  3 :  6.480789470790296 %\n",
      "Thema  4 :  60.48123863706242 %\n",
      "\n",
      "2 . Reviewtext:  perfect\n",
      "Thema  0 :  10.000006098898522 %\n",
      "Thema  1 :  10.000010369607276 %\n",
      "Thema  2 :  59.971827907572475 %\n",
      "Thema  3 :  10.000006983671312 %\n",
      "Thema  4 :  10.02814864025041 %\n",
      "\n",
      "3 . Reviewtext:  just lost another one - again  would someone please make these with a lanyard or a buoyant material around the wire  it works but since i lose so many nose clips it makes more since to use the cheapest one that works - not this\n",
      "Thema  0 :  9.07096620292476 %\n",
      "Thema  1 :  3.926188355820912 %\n",
      "Thema  2 :  3.941790133792242 %\n",
      "Thema  3 :  3.9666374620360565 %\n",
      "Thema  4 :  79.09441784542604 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in range(3):\n",
    "  print(x+1,\". Reviewtext: \", df_poc.iloc[x]['reviewText'])\n",
    "  for i,topic in enumerate(lda_top[x]):\n",
    "    print(\"Thema \",i,\": \",topic*100,\"%\")\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thema 0: \n",
      "knife advertise scope target sight \n",
      "Thema 1: \n",
      "gift shirt cute soccer em \n",
      "Thema 2: \n",
      "love perfect nice thank fit \n",
      "Thema 3: \n",
      "great good work product excellent \n",
      "Thema 4: \n",
      "great use well work like \n"
     ]
    }
   ],
   "source": [
    "vocab = vect.get_feature_names_out()\n",
    "for i, comp in enumerate(lda_model.components_):\n",
    "     vocab_comp = zip(vocab, comp)\n",
    "     sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:5]\n",
    "     print(\"Thema \"+str(i)+\": \")\n",
    "     for t in sorted_words:\n",
    "            print(t[0],end=\" \")\n",
    "            # print(\"\")\n",
    "     print('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training des Modells - LdaMulticore\n",
    "Der LDA Algorithmus von dem Paket sklearn nutzt nur einen Kern des Prozessors für die Berechnung. Dies führ dazu, dass die Berechnung von 1% des Datensatzes bereits 10 Minuten braucht. Ein effizenteres Modell wäre LdaMulticore von Gensim. Dieses nutzt mehrere Kerne des Prozessors wodurch die Berechnungen parallel zueinander laufen können. Im Test hat der Durchlauf dann auch nur einen Bruchteil einer Sekunde gebraucht."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Algorithmus               | Zeilen | Berechnungszeit |  \n",
    "|---------------------------|--------|-----------------|\n",
    "| LatentDirichletAllocation | 28399 | 10 Minutes      |  \n",
    "| LdaMulticore              | 28399 | 0.3 Minutes     | \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst werden alle Listen von Schlüsselwörtern der einzelnen Dokumente in eine Liste (data) hinzugefügt. Basierend darauf wird ein corpora.dictionary erstellt. Hier wird jedem Wort eine Id zugewiesen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_poc.reviewText_tokenize.values.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das corpora.Dictionary wird in eine Liste umkonvertiert, welches für jeden Text eine Liste aus Tupeln beinhaltet. Jedes Tupel besteht dabei aus der TokenId und der Anzahl der Vorkommen dieser Id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(data)\n",
    "\n",
    "#id2word.token2id   # print Dictionary\n",
    "#id2word.cfs        # frequency of ids\n",
    "#id2word.num_docs   # number of documents - hier: Zeilen im Dataframe\n",
    "#id2word.num_pos    # number of processed words\n",
    "\n",
    "corpus = [id2word.doc2bow(elem) for elem in data]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- corpus: Liste mit Listen von Tupel (TokenId, Anzahl der Vorkommen)\n",
    "- id2word: Mapping von ID der Wörter zu Wörter\n",
    "- num_topics: Anzahl an Themen welche erstellt werden sollen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpus=corpus, id2word=id2word, num_topics=5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untersuchung der Ergebnisse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für den ersten Blick werden die ersten drei Texte gedruckt und deren zugehörigen Anteile von Themen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . Reviewtext:  we are reviewing several sets of darts from viper  i am just learning the game and my husband used to play in a non-pro league  the blitz steel tips are awkward for me to hold comfortably because they are so streamlined but to him these are now his new favorites  he says they do exactly what he wants he loves the weight and slimness that viper has created here these are \"serious\" darts for the more advanced player\n",
      "Thema  2 :  39.24567401409149 %\n",
      "Thema  3 :  50.12723207473755 %\n",
      "Thema  4 :  9.45027843117714 %\n",
      "\n",
      "2 . Reviewtext:  perfect\n",
      "Thema  0 :  10.28885468840599 %\n",
      "Thema  1 :  10.079541802406311 %\n",
      "Thema  2 :  59.27603244781494 %\n",
      "Thema  3 :  10.201019793748856 %\n",
      "Thema  4 :  10.1545549929142 %\n",
      "\n",
      "3 . Reviewtext:  just lost another one - again  would someone please make these with a lanyard or a buoyant material around the wire  it works but since i lose so many nose clips it makes more since to use the cheapest one that works - not this\n",
      "Thema  0 :  96.71302437782288 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_text_topic(df, lda_model, id2word, num):\n",
    "    for i in range(num):\n",
    "        bow = id2word.doc2bow(df.iloc[i]['reviewText_tokenize'])\n",
    "        docu_topics = lda_model.get_document_topics(bow)\n",
    "\n",
    "        print(i+1,'. Reviewtext: ', df.iloc[i]['reviewText'])\n",
    "        for top in docu_topics:\n",
    "            print('Thema ',top[0],': ', top[1]*100,'%')\n",
    "        print()\n",
    "\n",
    "print_text_topic(df_poc, lda_model, id2word, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.015*\"well\" + 0.012*\"great\" + 0.010*\"work\" + 0.009*\"make\" + 0.009*\"use\" + 0.009*\"one\" + 0.008*\"bag\" + 0.008*\"fit\" + 0.008*\"love\" + 0.007*\"get\" + 0.007*\"like\" + 0.007*\"need\" + 0.006*\"good\" + 0.006*\"much\" + 0.005*\"keep\" + 0.005*\"buy\" + 0.004*\"knife\" + 0.004*\"better\" + 0.004*\"quality\" + 0.004*\"water\"'),\n",
       " (1,\n",
       "  '0.022*\"use\" + 0.013*\"work\" + 0.012*\"great\" + 0.011*\"get\" + 0.011*\"good\" + 0.009*\"product\" + 0.007*\"one\" + 0.007*\"well\" + 0.007*\"buy\" + 0.007*\"time\" + 0.006*\"make\" + 0.006*\"price\" + 0.005*\"like\" + 0.005*\"love\" + 0.005*\"go\" + 0.005*\"come\" + 0.004*\"need\" + 0.004*\"quality\" + 0.004*\"would\" + 0.004*\"take\"'),\n",
       " (2,\n",
       "  '0.012*\"great\" + 0.010*\"would\" + 0.010*\"use\" + 0.009*\"like\" + 0.009*\"fit\" + 0.009*\"one\" + 0.008*\"work\" + 0.008*\"buy\" + 0.007*\"get\" + 0.006*\"well\" + 0.006*\"time\" + 0.006*\"make\" + 0.006*\"size\" + 0.006*\"bike\" + 0.005*\"light\" + 0.005*\"put\" + 0.005*\"good\" + 0.005*\"perfect\" + 0.005*\"product\" + 0.004*\"bag\"'),\n",
       " (3,\n",
       "  '0.017*\"great\" + 0.015*\"use\" + 0.011*\"good\" + 0.011*\"get\" + 0.010*\"work\" + 0.009*\"fit\" + 0.007*\"one\" + 0.006*\"well\" + 0.006*\"quality\" + 0.006*\"easy\" + 0.006*\"little\" + 0.005*\"product\" + 0.005*\"buy\" + 0.005*\"like\" + 0.005*\"look\" + 0.005*\"make\" + 0.004*\"light\" + 0.004*\"size\" + 0.004*\"hold\" + 0.004*\"want\"'),\n",
       " (4,\n",
       "  '0.011*\"use\" + 0.011*\"good\" + 0.011*\"get\" + 0.011*\"like\" + 0.010*\"great\" + 0.009*\"nice\" + 0.008*\"make\" + 0.007*\"would\" + 0.007*\"look\" + 0.007*\"love\" + 0.007*\"one\" + 0.006*\"well\" + 0.006*\"go\" + 0.006*\"work\" + 0.006*\"really\" + 0.006*\"buy\" + 0.006*\"water\" + 0.005*\"size\" + 0.005*\"little\" + 0.005*\"need\"')]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics(5, 20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisierung\n",
    "Um zu prüfen, welche Wörter bei welchen Thema den stärksten Einfluss haben, sollen die Zahlen normiert werden. Über die Methode get_topic_terms wird für das gegebene Thema eine Liste mit Tupeln erstellt, welche die Id eines Wortes sowie desen Wert beinhaltet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(155, 0.014773757),\n",
       " (262, 0.011736456),\n",
       " (49, 0.010088598),\n",
       " (40, 0.00927833),\n",
       " (28, 0.009038642),\n",
       " (44, 0.008706187),\n",
       " (160, 0.008413656),\n",
       " (56, 0.008093723),\n",
       " (13, 0.0077996124),\n",
       " (60, 0.0073819384),\n",
       " (263, 0.006844423),\n",
       " (240, 0.0065828236),\n",
       " (51, 0.0064272215),\n",
       " (67, 0.0059461775),\n",
       " (189, 0.0053895335),\n",
       " (161, 0.0050977706),\n",
       " (1206, 0.0043455227),\n",
       " (103, 0.004019929),\n",
       " (143, 0.0038776605),\n",
       " (376, 0.0036612933)]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_zero = lda_model.get_topic_terms(0, 20)\n",
    "topic_one = lda_model.get_topic_terms(1, 20)\n",
    "topic_two = lda_model.get_topic_terms(2, 20)\n",
    "topic_three = lda_model.get_topic_terms(3, 20)\n",
    "topic_four = lda_model.get_topic_terms(4, 20)\n",
    "\n",
    "topic_zero\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Listen sollen jetzt in ein Dataframe gespeichert werden, mit den Id der Wörter als Spalten Labels und die Themen als Reihen Labels. Dafür werden die Listen mit Tupel in Dictionarys umgewandelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{155: 0.014773757,\n",
       " 262: 0.011736456,\n",
       " 49: 0.010088598,\n",
       " 40: 0.00927833,\n",
       " 28: 0.009038642,\n",
       " 44: 0.008706187,\n",
       " 160: 0.008413656,\n",
       " 56: 0.008093723,\n",
       " 13: 0.0077996124,\n",
       " 60: 0.0073819384,\n",
       " 263: 0.006844423,\n",
       " 240: 0.0065828236,\n",
       " 51: 0.0064272215,\n",
       " 67: 0.0059461775,\n",
       " 189: 0.0053895335,\n",
       " 161: 0.0050977706,\n",
       " 1206: 0.0043455227,\n",
       " 103: 0.004019929,\n",
       " 143: 0.0038776605,\n",
       " 376: 0.0036612933}"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_list = []\n",
    "for elem in [topic_zero, topic_one, topic_two, topic_three, topic_four]:\n",
    "    dic = dict((x,y) for x,y in elem)\n",
    "    dic_list.append(dic)\n",
    "dic_list[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>155</th>\n",
       "      <th>262</th>\n",
       "      <th>49</th>\n",
       "      <th>40</th>\n",
       "      <th>28</th>\n",
       "      <th>44</th>\n",
       "      <th>160</th>\n",
       "      <th>56</th>\n",
       "      <th>13</th>\n",
       "      <th>60</th>\n",
       "      <th>...</th>\n",
       "      <th>131</th>\n",
       "      <th>244</th>\n",
       "      <th>32</th>\n",
       "      <th>162</th>\n",
       "      <th>275</th>\n",
       "      <th>478</th>\n",
       "      <th>9</th>\n",
       "      <th>30</th>\n",
       "      <th>276</th>\n",
       "      <th>525</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014774</td>\n",
       "      <td>0.011736</td>\n",
       "      <td>0.010089</td>\n",
       "      <td>0.009278</td>\n",
       "      <td>0.009039</td>\n",
       "      <td>0.008706</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006909</td>\n",
       "      <td>0.012127</td>\n",
       "      <td>0.013018</td>\n",
       "      <td>0.006326</td>\n",
       "      <td>0.021883</td>\n",
       "      <td>0.007226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004891</td>\n",
       "      <td>0.011316</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006441</td>\n",
       "      <td>0.012050</td>\n",
       "      <td>0.007764</td>\n",
       "      <td>0.005851</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.009071</td>\n",
       "      <td>0.004438</td>\n",
       "      <td>0.009187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005227</td>\n",
       "      <td>0.004802</td>\n",
       "      <td>0.004773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006435</td>\n",
       "      <td>0.017052</td>\n",
       "      <td>0.010166</td>\n",
       "      <td>0.004995</td>\n",
       "      <td>0.015323</td>\n",
       "      <td>0.007441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005718</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.005132</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006461</td>\n",
       "      <td>0.010473</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>0.008107</td>\n",
       "      <td>0.011397</td>\n",
       "      <td>0.006749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006826</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004685</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00938</td>\n",
       "      <td>0.005911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        155       262       49        40        28        44        160  \\\n",
       "0  0.014774  0.011736  0.010089  0.009278  0.009039  0.008706  0.008414   \n",
       "1  0.006909  0.012127  0.013018  0.006326  0.021883  0.007226       NaN   \n",
       "2  0.006441  0.012050  0.007764  0.005851  0.009782  0.009071  0.004438   \n",
       "3  0.006435  0.017052  0.010166  0.004995  0.015323  0.007441       NaN   \n",
       "4  0.006461  0.010473  0.006179  0.008107  0.011397  0.006749       NaN   \n",
       "\n",
       "        56        13        60   ...       131       244       32        162  \\\n",
       "0  0.008094  0.007800  0.007382  ...       NaN       NaN       NaN       NaN   \n",
       "1       NaN  0.004891  0.011316  ...       NaN       NaN       NaN       NaN   \n",
       "2  0.009187       NaN  0.006853  ...  0.005227  0.004802  0.004773       NaN   \n",
       "3  0.009493       NaN  0.010538  ...  0.004460       NaN       NaN  0.005718   \n",
       "4       NaN  0.006826  0.010823  ...       NaN       NaN       NaN       NaN   \n",
       "\n",
       "        275       478       9         30       276       525  \n",
       "0       NaN       NaN       NaN       NaN      NaN       NaN  \n",
       "1       NaN       NaN       NaN       NaN      NaN       NaN  \n",
       "2       NaN       NaN       NaN       NaN      NaN       NaN  \n",
       "3  0.005538  0.005132  0.003962  0.003938      NaN       NaN  \n",
       "4  0.004685  0.007139       NaN       NaN  0.00938  0.005911  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic = pd.DataFrame.from_records(dic_list)\n",
    "df_topic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Lesbarkeit zu verbessern werden die Wörter-Ids durch die tatsächlichen Wörter ersetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>well</th>\n",
       "      <th>great</th>\n",
       "      <th>work</th>\n",
       "      <th>make</th>\n",
       "      <th>use</th>\n",
       "      <th>one</th>\n",
       "      <th>bag</th>\n",
       "      <th>fit</th>\n",
       "      <th>love</th>\n",
       "      <th>get</th>\n",
       "      <th>...</th>\n",
       "      <th>light</th>\n",
       "      <th>put</th>\n",
       "      <th>perfect</th>\n",
       "      <th>easy</th>\n",
       "      <th>little</th>\n",
       "      <th>look</th>\n",
       "      <th>hold</th>\n",
       "      <th>want</th>\n",
       "      <th>nice</th>\n",
       "      <th>really</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014774</td>\n",
       "      <td>0.011736</td>\n",
       "      <td>0.010089</td>\n",
       "      <td>0.009278</td>\n",
       "      <td>0.009039</td>\n",
       "      <td>0.008706</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006909</td>\n",
       "      <td>0.012127</td>\n",
       "      <td>0.013018</td>\n",
       "      <td>0.006326</td>\n",
       "      <td>0.021883</td>\n",
       "      <td>0.007226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004891</td>\n",
       "      <td>0.011316</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006441</td>\n",
       "      <td>0.012050</td>\n",
       "      <td>0.007764</td>\n",
       "      <td>0.005851</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.009071</td>\n",
       "      <td>0.004438</td>\n",
       "      <td>0.009187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005227</td>\n",
       "      <td>0.004802</td>\n",
       "      <td>0.004773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006435</td>\n",
       "      <td>0.017052</td>\n",
       "      <td>0.010166</td>\n",
       "      <td>0.004995</td>\n",
       "      <td>0.015323</td>\n",
       "      <td>0.007441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005718</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.005132</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006461</td>\n",
       "      <td>0.010473</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>0.008107</td>\n",
       "      <td>0.011397</td>\n",
       "      <td>0.006749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006826</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004685</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00938</td>\n",
       "      <td>0.005911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       well     great      work      make       use       one       bag  \\\n",
       "0  0.014774  0.011736  0.010089  0.009278  0.009039  0.008706  0.008414   \n",
       "1  0.006909  0.012127  0.013018  0.006326  0.021883  0.007226       NaN   \n",
       "2  0.006441  0.012050  0.007764  0.005851  0.009782  0.009071  0.004438   \n",
       "3  0.006435  0.017052  0.010166  0.004995  0.015323  0.007441       NaN   \n",
       "4  0.006461  0.010473  0.006179  0.008107  0.011397  0.006749       NaN   \n",
       "\n",
       "        fit      love       get  ...     light       put   perfect      easy  \\\n",
       "0  0.008094  0.007800  0.007382  ...       NaN       NaN       NaN       NaN   \n",
       "1       NaN  0.004891  0.011316  ...       NaN       NaN       NaN       NaN   \n",
       "2  0.009187       NaN  0.006853  ...  0.005227  0.004802  0.004773       NaN   \n",
       "3  0.009493       NaN  0.010538  ...  0.004460       NaN       NaN  0.005718   \n",
       "4       NaN  0.006826  0.010823  ...       NaN       NaN       NaN       NaN   \n",
       "\n",
       "     little      look      hold      want     nice    really  \n",
       "0       NaN       NaN       NaN       NaN      NaN       NaN  \n",
       "1       NaN       NaN       NaN       NaN      NaN       NaN  \n",
       "2       NaN       NaN       NaN       NaN      NaN       NaN  \n",
       "3  0.005538  0.005132  0.003962  0.003938      NaN       NaN  \n",
       "4  0.004685  0.007139       NaN       NaN  0.00938  0.005911  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = []\n",
    "for elem in df_topic.columns:\n",
    "    words.append(id2word.get(elem))\n",
    "df_topic.columns = words\n",
    "\n",
    "df_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>well</th>\n",
       "      <th>great</th>\n",
       "      <th>work</th>\n",
       "      <th>make</th>\n",
       "      <th>use</th>\n",
       "      <th>one</th>\n",
       "      <th>bag</th>\n",
       "      <th>fit</th>\n",
       "      <th>love</th>\n",
       "      <th>get</th>\n",
       "      <th>...</th>\n",
       "      <th>light</th>\n",
       "      <th>put</th>\n",
       "      <th>perfect</th>\n",
       "      <th>easy</th>\n",
       "      <th>little</th>\n",
       "      <th>look</th>\n",
       "      <th>hold</th>\n",
       "      <th>want</th>\n",
       "      <th>nice</th>\n",
       "      <th>really</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.192051</td>\n",
       "      <td>0.571706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.118588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.056778</td>\n",
       "      <td>0.251340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.310652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.205585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.627112</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.239685</td>\n",
       "      <td>0.231797</td>\n",
       "      <td>0.199699</td>\n",
       "      <td>0.057846</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.527514</td>\n",
       "      <td>0.967779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.583079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489293</td>\n",
       "      <td>0.297831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.825729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.71879</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.726619</td>\n",
       "      <td>0.183601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.875213</td>\n",
       "      <td>0.889641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.846107</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       well     great      work      make       use       one       bag  \\\n",
       "0  1.000000  0.192051  0.571706  1.000000  0.000000  0.842937  1.000000   \n",
       "1  0.056778  0.251340  1.000000  0.310652  1.000000  0.205585  0.000000   \n",
       "2  0.000634  0.239685  0.231797  0.199699  0.057846  1.000000  0.527514   \n",
       "3  0.000000  1.000000  0.583079  0.000000  0.489293  0.297831  0.000000   \n",
       "4  0.003135  0.000000  0.000000  0.726619  0.183601  0.000000  0.000000   \n",
       "\n",
       "        fit      love       get  ...     light  put  perfect  easy    little  \\\n",
       "0  0.852636  1.000000  0.118588  ...  0.000000  0.0      0.0   0.0  0.000000   \n",
       "1  0.000000  0.627112  1.000000  ...  0.000000  0.0      0.0   0.0  0.000000   \n",
       "2  0.967779  0.000000  0.000000  ...  1.000000  1.0      1.0   0.0  0.000000   \n",
       "3  1.000000  0.000000  0.825729  ...  0.853274  0.0      0.0   1.0  1.000000   \n",
       "4  0.000000  0.875213  0.889641  ...  0.000000  0.0      0.0   0.0  0.846107   \n",
       "\n",
       "      look  hold  want  nice  really  \n",
       "0  0.00000   0.0   0.0   0.0     0.0  \n",
       "1  0.00000   0.0   0.0   0.0     0.0  \n",
       "2  0.00000   0.0   0.0   0.0     0.0  \n",
       "3  0.71879   1.0   1.0   0.0     0.0  \n",
       "4  1.00000   0.0   0.0   1.0     1.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic = df_topic.replace(np.nan, 0)\n",
    "for elem in df_topic.columns:\n",
    "    df_topic[elem] = (df_topic[elem] - df_topic[elem].min()) / (df_topic[elem].max() - df_topic[elem].min())    \n",
    "\n",
    "df_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thema  0\n",
      "well      1.0\n",
      "make      1.0\n",
      "bag       1.0\n",
      "love      1.0\n",
      "need      1.0\n",
      "much      1.0\n",
      "keep      1.0\n",
      "knife     1.0\n",
      "better    1.0\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "Thema  1\n",
      "work       1.0\n",
      "use        1.0\n",
      "get        1.0\n",
      "product    1.0\n",
      "time       1.0\n",
      "price      1.0\n",
      "come       1.0\n",
      "take       1.0\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "Thema  2\n",
      "one        1.0\n",
      "buy        1.0\n",
      "would      1.0\n",
      "size       1.0\n",
      "bike       1.0\n",
      "light      1.0\n",
      "put        1.0\n",
      "perfect    1.0\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "Thema  3\n",
      "great      1.0\n",
      "fit        1.0\n",
      "good       1.0\n",
      "quality    1.0\n",
      "easy       1.0\n",
      "little     1.0\n",
      "hold       1.0\n",
      "want       1.0\n",
      "Name: 3, dtype: float64\n",
      "\n",
      "Thema  4\n",
      "like      1.0\n",
      "water     1.0\n",
      "go        1.0\n",
      "look      1.0\n",
      "nice      1.0\n",
      "really    1.0\n",
      "Name: 4, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('Thema ',i)\n",
    "    print(df_topic.loc[df_topic.index[i]].loc[lambda x : x == 1])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df_topic.columns:\n",
    "#     print(col,' ' ,len(df_topic[col].unique()))\n",
    "# df_nan = df_topic[df_topic.columns[~df_topic.isnull().any()]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bestimmung des Hauptthemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Main Topic in seperate column\n",
    "def maintopic(df, lda_model):\n",
    "    scores = []\n",
    "    topic = []\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    #Iteration über alle Dokumente\n",
    "    for elem in df['reviewText_tokenize']:\n",
    "        bow = id2word.doc2bow(elem)\n",
    "        docu_topics = lda_model.get_document_topics(bow)\n",
    "        topic_scores = []\n",
    "        topic_number = []\n",
    "        # alle Topics von einen Dokument in eine Liste abspeichern\n",
    "        for elem in docu_topics:\n",
    "            topic_scores.append(elem[1])\n",
    "            topic_number.append(elem[0])\n",
    "        main_score = max(topic_scores)\n",
    "        main_topic = topic_number[topic_scores.index(main_score)]\n",
    "\n",
    "        scores.append(main_score)\n",
    "        topic.append(main_topic)\n",
    "\n",
    "        # print(topic_scores)\n",
    "        # print(topic_number)\n",
    "\n",
    "        # print(scores)\n",
    "        # print(topic)\n",
    "\n",
    "    df['maintopic'] = topic\n",
    "    df['mainscore'] = scores\n",
    "    # return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "maintopic(df_poc, lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewText_tokenize</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "      <th>reviewText_cleaned</th>\n",
       "      <th>maintopic</th>\n",
       "      <th>mainscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1195218</th>\n",
       "      <td>A36JK2BSXS0U43</td>\n",
       "      <td>1517788800</td>\n",
       "      <td>B005NATM06</td>\n",
       "      <td>5</td>\n",
       "      <td>we are reviewing several sets of darts from vi...</td>\n",
       "      <td>[review, several, set, dart, viper, learn, gam...</td>\n",
       "      <td>[several, dart, non, pro, tip, awkward, comfor...</td>\n",
       "      <td>[viper, learn, game, husband, use, play, leagu...</td>\n",
       "      <td>[review, set, hold, say, want]</td>\n",
       "      <td>review several set dart viper learn game husba...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.511848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138622</th>\n",
       "      <td>A374H5DSRDUT1P</td>\n",
       "      <td>1408147200</td>\n",
       "      <td>B000F7VV42</td>\n",
       "      <td>5</td>\n",
       "      <td>perfect</td>\n",
       "      <td>[perfect]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[perfect]</td>\n",
       "      <td>[]</td>\n",
       "      <td>perfect</td>\n",
       "      <td>2</td>\n",
       "      <td>0.592782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45540</th>\n",
       "      <td>AU52E1PVI59D0</td>\n",
       "      <td>1462060800</td>\n",
       "      <td>B00070QEN0</td>\n",
       "      <td>2</td>\n",
       "      <td>just lost another one - again  would someone p...</td>\n",
       "      <td>[lose, another, one, would, someone, please, m...</td>\n",
       "      <td>[another, would, lanyard, buoyant, around, sin...</td>\n",
       "      <td>[one, someone, material, wire, work, clip, use...</td>\n",
       "      <td>[lose, please, make, make, cheapest]</td>\n",
       "      <td>lose another one would someone please make lan...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.967138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893937</th>\n",
       "      <td>A2TM7I63LF51L1</td>\n",
       "      <td>1487289600</td>\n",
       "      <td>B00M8MLSJ0</td>\n",
       "      <td>5</td>\n",
       "      <td>works good</td>\n",
       "      <td>[work, good]</td>\n",
       "      <td>[good]</td>\n",
       "      <td>[work]</td>\n",
       "      <td>[]</td>\n",
       "      <td>work good</td>\n",
       "      <td>1</td>\n",
       "      <td>0.726865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914910</th>\n",
       "      <td>AXCRLIMPYXWUG</td>\n",
       "      <td>1467072000</td>\n",
       "      <td>B00MX89O2C</td>\n",
       "      <td>3</td>\n",
       "      <td>i got this lock because its a small size so it...</td>\n",
       "      <td>[get, lock, small, size, lighter, use, want, l...</td>\n",
       "      <td>[lock, small, bike, forever, lock, one, right,...</td>\n",
       "      <td>[size, lighter, use, lock, frame, rack, work, ...</td>\n",
       "      <td>[get, want, take, get, go, find]</td>\n",
       "      <td>get lock small size lighter use want lock fram...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.982898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             reviewerID  unixReviewTime        asin  overall  \\\n",
       "1195218  A36JK2BSXS0U43      1517788800  B005NATM06        5   \n",
       "138622   A374H5DSRDUT1P      1408147200  B000F7VV42        5   \n",
       "45540     AU52E1PVI59D0      1462060800  B00070QEN0        2   \n",
       "1893937  A2TM7I63LF51L1      1487289600  B00M8MLSJ0        5   \n",
       "1914910   AXCRLIMPYXWUG      1467072000  B00MX89O2C        3   \n",
       "\n",
       "                                                reviewText  \\\n",
       "1195218  we are reviewing several sets of darts from vi...   \n",
       "138622                                             perfect   \n",
       "45540    just lost another one - again  would someone p...   \n",
       "1893937                                         works good   \n",
       "1914910  i got this lock because its a small size so it...   \n",
       "\n",
       "                                       reviewText_tokenize  \\\n",
       "1195218  [review, several, set, dart, viper, learn, gam...   \n",
       "138622                                           [perfect]   \n",
       "45540    [lose, another, one, would, someone, please, m...   \n",
       "1893937                                       [work, good]   \n",
       "1914910  [get, lock, small, size, lighter, use, want, l...   \n",
       "\n",
       "                                                adjectives  \\\n",
       "1195218  [several, dart, non, pro, tip, awkward, comfor...   \n",
       "138622                                                  []   \n",
       "45540    [another, would, lanyard, buoyant, around, sin...   \n",
       "1893937                                             [good]   \n",
       "1914910  [lock, small, bike, forever, lock, one, right,...   \n",
       "\n",
       "                                                     nouns  \\\n",
       "1195218  [viper, learn, game, husband, use, play, leagu...   \n",
       "138622                                           [perfect]   \n",
       "45540    [one, someone, material, wire, work, clip, use...   \n",
       "1893937                                             [work]   \n",
       "1914910  [size, lighter, use, lock, frame, rack, work, ...   \n",
       "\n",
       "                                        verbs  \\\n",
       "1195218        [review, set, hold, say, want]   \n",
       "138622                                     []   \n",
       "45540    [lose, please, make, make, cheapest]   \n",
       "1893937                                    []   \n",
       "1914910      [get, want, take, get, go, find]   \n",
       "\n",
       "                                        reviewText_cleaned  maintopic  \\\n",
       "1195218  review several set dart viper learn game husba...          3   \n",
       "138622                                             perfect          2   \n",
       "45540    lose another one would someone please make lan...          0   \n",
       "1893937                                          work good          1   \n",
       "1914910  get lock small size lighter use want lock fram...          3   \n",
       "\n",
       "         mainscore  \n",
       "1195218   0.511848  \n",
       "138622    0.592782  \n",
       "45540     0.967138  \n",
       "1893937   0.726865  \n",
       "1914910   0.982898  "
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poc.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fürs erste soll die Verteilung der Themen betrachtet werden.\n",
    "!-- Erkenntnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4486\n",
       "1    5636\n",
       "2    6317\n",
       "3    5568\n",
       "4    6392\n",
       "Name: maintopic, dtype: int64"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poc['maintopic'].value_counts().sort_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wertebereiche von mainscores\n",
    "Wie im Histogram zu sehen ist, haben die meisten Dokumente einen Score von 0.7 und höher.\n",
    "Wenn der Mainscore nahe an 0.2 liegt, dann bedeutet dies, dass die Themen im Dokument sehr gleichmäßig verteilt sind. Diese könnten für die weitere Analyse entfernt werden, weil diese nicht sehr aussagekrägtig für ein Thema sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def transparent_histogram(df):\n",
    "    for i in range(5):\n",
    "        a = df.loc[df['maintopic'] == i, 'mainscore']\n",
    "        a.sort_values()\n",
    "        #a.hist()\n",
    "        a.hist(fc=(0, 0, 1, 0.5))\n",
    "\n",
    "transparent_histogram(df_poc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betrachtung von MainTopic - Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewText_tokenize</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "      <th>reviewText_cleaned</th>\n",
       "      <th>maintopic</th>\n",
       "      <th>mainscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1195218</th>\n",
       "      <td>A36JK2BSXS0U43</td>\n",
       "      <td>1517788800</td>\n",
       "      <td>B005NATM06</td>\n",
       "      <td>5</td>\n",
       "      <td>we are reviewing several sets of darts from vi...</td>\n",
       "      <td>[review, several, set, dart, viper, learn, gam...</td>\n",
       "      <td>[several, dart, non, pro, tip, awkward, comfor...</td>\n",
       "      <td>[viper, learn, game, husband, use, play, leagu...</td>\n",
       "      <td>[review, set, hold, say, want]</td>\n",
       "      <td>review several set dart viper learn game husba...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.511848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138622</th>\n",
       "      <td>A374H5DSRDUT1P</td>\n",
       "      <td>1408147200</td>\n",
       "      <td>B000F7VV42</td>\n",
       "      <td>5</td>\n",
       "      <td>perfect</td>\n",
       "      <td>[perfect]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[perfect]</td>\n",
       "      <td>[]</td>\n",
       "      <td>perfect</td>\n",
       "      <td>2</td>\n",
       "      <td>0.592782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45540</th>\n",
       "      <td>AU52E1PVI59D0</td>\n",
       "      <td>1462060800</td>\n",
       "      <td>B00070QEN0</td>\n",
       "      <td>2</td>\n",
       "      <td>just lost another one - again  would someone p...</td>\n",
       "      <td>[lose, another, one, would, someone, please, m...</td>\n",
       "      <td>[another, would, lanyard, buoyant, around, sin...</td>\n",
       "      <td>[one, someone, material, wire, work, clip, use...</td>\n",
       "      <td>[lose, please, make, make, cheapest]</td>\n",
       "      <td>lose another one would someone please make lan...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.967138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893937</th>\n",
       "      <td>A2TM7I63LF51L1</td>\n",
       "      <td>1487289600</td>\n",
       "      <td>B00M8MLSJ0</td>\n",
       "      <td>5</td>\n",
       "      <td>works good</td>\n",
       "      <td>[work, good]</td>\n",
       "      <td>[good]</td>\n",
       "      <td>[work]</td>\n",
       "      <td>[]</td>\n",
       "      <td>work good</td>\n",
       "      <td>1</td>\n",
       "      <td>0.726865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914910</th>\n",
       "      <td>AXCRLIMPYXWUG</td>\n",
       "      <td>1467072000</td>\n",
       "      <td>B00MX89O2C</td>\n",
       "      <td>3</td>\n",
       "      <td>i got this lock because its a small size so it...</td>\n",
       "      <td>[get, lock, small, size, lighter, use, want, l...</td>\n",
       "      <td>[lock, small, bike, forever, lock, one, right,...</td>\n",
       "      <td>[size, lighter, use, lock, frame, rack, work, ...</td>\n",
       "      <td>[get, want, take, get, go, find]</td>\n",
       "      <td>get lock small size lighter use want lock fram...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.982898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             reviewerID  unixReviewTime        asin  overall  \\\n",
       "1195218  A36JK2BSXS0U43      1517788800  B005NATM06        5   \n",
       "138622   A374H5DSRDUT1P      1408147200  B000F7VV42        5   \n",
       "45540     AU52E1PVI59D0      1462060800  B00070QEN0        2   \n",
       "1893937  A2TM7I63LF51L1      1487289600  B00M8MLSJ0        5   \n",
       "1914910   AXCRLIMPYXWUG      1467072000  B00MX89O2C        3   \n",
       "\n",
       "                                                reviewText  \\\n",
       "1195218  we are reviewing several sets of darts from vi...   \n",
       "138622                                             perfect   \n",
       "45540    just lost another one - again  would someone p...   \n",
       "1893937                                         works good   \n",
       "1914910  i got this lock because its a small size so it...   \n",
       "\n",
       "                                       reviewText_tokenize  \\\n",
       "1195218  [review, several, set, dart, viper, learn, gam...   \n",
       "138622                                           [perfect]   \n",
       "45540    [lose, another, one, would, someone, please, m...   \n",
       "1893937                                       [work, good]   \n",
       "1914910  [get, lock, small, size, lighter, use, want, l...   \n",
       "\n",
       "                                                adjectives  \\\n",
       "1195218  [several, dart, non, pro, tip, awkward, comfor...   \n",
       "138622                                                  []   \n",
       "45540    [another, would, lanyard, buoyant, around, sin...   \n",
       "1893937                                             [good]   \n",
       "1914910  [lock, small, bike, forever, lock, one, right,...   \n",
       "\n",
       "                                                     nouns  \\\n",
       "1195218  [viper, learn, game, husband, use, play, leagu...   \n",
       "138622                                           [perfect]   \n",
       "45540    [one, someone, material, wire, work, clip, use...   \n",
       "1893937                                             [work]   \n",
       "1914910  [size, lighter, use, lock, frame, rack, work, ...   \n",
       "\n",
       "                                        verbs  \\\n",
       "1195218        [review, set, hold, say, want]   \n",
       "138622                                     []   \n",
       "45540    [lose, please, make, make, cheapest]   \n",
       "1893937                                    []   \n",
       "1914910      [get, want, take, get, go, find]   \n",
       "\n",
       "                                        reviewText_cleaned  maintopic  \\\n",
       "1195218  review several set dart viper learn game husba...          3   \n",
       "138622                                             perfect          2   \n",
       "45540    lose another one would someone please make lan...          0   \n",
       "1893937                                          work good          1   \n",
       "1914910  get lock small size lighter use want lock fram...          3   \n",
       "\n",
       "         mainscore  \n",
       "1195218   0.511848  \n",
       "138622    0.592782  \n",
       "45540     0.967138  \n",
       "1893937   0.726865  \n",
       "1914910   0.982898  "
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thema  0  hat eine durchschnittliche Bewertung von  4.515827017387427\n",
      "Thema  1  hat eine durchschnittliche Bewertung von  4.372427253371185\n",
      "Thema  2  hat eine durchschnittliche Bewertung von  4.357131549786291\n",
      "Thema  3  hat eine durchschnittliche Bewertung von  4.48742816091954\n",
      "Thema  4  hat eine durchschnittliche Bewertung von  4.337453066332916\n"
     ]
    }
   ],
   "source": [
    "def print_avg_overall_for_maintopic(df):\n",
    "    for i in range(5):\n",
    "        avg = df.loc[df['maintopic'] == i, 'overall'].mean()\n",
    "        print('Thema ',i, ' hat eine durchschnittliche Bewertung von ', avg)\n",
    "print_avg_overall_for_maintopic(df_poc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Unterschiede zwischen den Durchschnittswerten ist minimal, kann aber bei weiteren Fällen nochmal betrachtet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thema  0\n",
      "Anteil von 1*:  2.942487739634418 %\n",
      "Anteil von 5*:  72.2246990637539 %\n",
      "Thema  1\n",
      "Anteil von 1*:  5.0745209368346345 %\n",
      "Anteil von 5*:  67.902767920511 %\n",
      "Thema  2\n",
      "Anteil von 1*:  4.701598860218458 %\n",
      "Anteil von 5*:  65.66408105113186 %\n",
      "Thema  3\n",
      "Anteil von 1*:  3.3045977011494254 %\n",
      "Anteil von 5*:  70.61781609195403 %\n",
      "Thema  4\n",
      "Anteil von 1*:  4.005006257822278 %\n",
      "Anteil von 5*:  63.21964956195244 %\n"
     ]
    }
   ],
   "source": [
    "def print_proportion_overall(df):\n",
    "    for i in range(5):\n",
    "        print('Thema ',i)\n",
    "        counts = df.loc[df['maintopic'] == i, 'overall'].value_counts()\n",
    "        low = counts[1]/counts.sum()\n",
    "        high = counts[5]/counts.sum()\n",
    "        # print(df.loc[df['maintopic'] == i, 'overall'].value_counts().sum())\n",
    "        print('Anteil von 1*: ',low*100,'%')\n",
    "        print('Anteil von 5*: ',high*100,'%')\n",
    "        \n",
    "print_proportion_overall(df_poc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Unterschiede sind auch hier minimal. Ein direkter Zusammenhang zwischen Topic und Bewertung scheint es nicht zu geben."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung mit pyLDAavis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ha Mi Duong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyLDAvis\\_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el2053623725620009606193091917\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el2053623725620009606193091917_data = {\"mdsDat\": {\"x\": [-0.0026057401686605474, -0.008082439017508247, 0.017858767295519835, 0.016619640722140738, -0.02379022883149176], \"y\": [0.005175093918527106, 0.023668752817890625, -0.010134801185750825, -0.00146774088089033, -0.017241304669776577], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [27.702886422869895, 23.38732040886134, 19.07269286385471, 16.239382639050785, 13.597717665363273]}, \"tinfo\": {\"Term\": [\"well\", \"use\", \"bag\", \"product\", \"work\", \"good\", \"love\", \"great\", \"fit\", \"nice\", \"get\", \"make\", \"knife\", \"much\", \"water\", \"quality\", \"need\", \"keep\", \"perfect\", \"one\", \"expect\", \"best\", \"better\", \"easy\", \"time\", \"look\", \"scope\", \"little\", \"bottle\", \"short\", \"castelli\", \"countersink\", \"turf\", \"ar556\", \"prefect\", \"336\", \"hum\", \"customizable\", \"contraption\", \"crow\", \"watery\", \"exelent\", \"joggers\", \"redskins\", \"xx1\", \"deny\", \"aok\", \"deterioration\", \"hs\", \"canteens\", \"1200lm\", \"israeli\", \"unsurpassed\", \"participate\", \"pity\", \"640\", \"jsb\", \"gostik\", \"boresnakes\", \"scalpel\", \"2xl\", \"frogg\", \"reccomend\", \"triathlon\", \"rd\", \"perfectly\", \"tumbler\", \"would\", \"bike\", \"put\", \"perfect\", \"tent\", \"zipper\", \"holster\", \"maxpedition\", \"coffee\", \"mountain\", \"clean\", \"hoppes\", \"barbell\", \"fit\", \"weight\", \"comfortable\", \"back\", \"time\", \"glock\", \"size\", \"light\", \"bite\", \"belt\", \"pocket\", \"front\", \"like\", \"camp\", \"buy\", \"one\", \"try\", \"husband\", \"see\", \"kit\", \"bag\", \"great\", \"take\", \"first\", \"price\", \"work\", \"product\", \"use\", \"well\", \"make\", \"little\", \"get\", \"also\", \"small\", \"need\", \"go\", \"come\", \"look\", \"good\", \"love\", \"dental\", \"kokanee\", \"dallas\", \"yankee\", \"leafy\", \"dc\", \"thomson\", \"aac\", \"leonard\", \"crud\", \"44cm\", \"sensei\", \"642\", \"stationary\", \"builder\", \"operations\", \"sofft\", \"withings\", \"wight\", \"chromium\", \"cf\", \"xxl\", \"shorty\", \"batman\", \"8lb\", \"lenght\", \"snd\", \"grin\", \"tombstone\", \"929\", \"bat\", \"de\", \"cowboys\", \"scosche\", \"fond\", \"sock\", \"nice\", \"short\", \"capris\", \"rod\", \"kershaw\", \"water\", \"mat\", \"cutter\", \"feel\", \"look\", \"really\", \"pillow\", \"recommend\", \"like\", \"wear\", \"son\", \"color\", \"love\", \"go\", \"seat\", \"good\", \"bottle\", \"purchase\", \"get\", \"think\", \"knife\", \"make\", \"sweat\", \"would\", \"highly\", \"ball\", \"size\", \"also\", \"little\", \"2\", \"use\", \"great\", \"need\", \"one\", \"buy\", \"well\", \"work\", \"easy\", \"price\", \"fit\", \"quality\", \"ak47\", \"civic\", \"rocker\", \"countless\", \"excellant\", \"wive\", \"nissan\", \"imr\", \"sanitary\", \"roger\", \"talley\", \"tomato\", \"smartwool\", \"82a\", \"tomatoes\", \"tourna\", \"packers\", \"drawstrings\", \"ts\", \"mystic\", \"efficent\", \"20000\", \"ilbe\", \"variations\", \"soothe\", \"wich\", \"talon\", \"stil\", \"505\", \"boulders\", \"excelent\", \"unreal\", \"20s\", \"xtr\", \"thompson\", \"100lbs\", \"weaver\", \"electricity\", \"pc\", \"flake\", \"product\", \"junk\", \"advertise\", \"use\", \"bracelets\", \"work\", \"fog\", \"air\", \"time\", \"price\", \"day\", \"grip\", \"bow\", \"get\", \"good\", \"range\", \"delivery\", \"arrows\", \"link\", \"battery\", \"foam\", \"shoot\", \"two\", \"maybe\", \"come\", \"bear\", \"great\", \"end\", \"buy\", \"set\", \"even\", \"new\", \"solid\", \"find\", \"one\", \"well\", \"make\", \"love\", \"go\", \"take\", \"quality\", \"expect\", \"need\", \"think\", \"say\", \"like\", \"easy\", \"try\", \"much\", \"really\", \"would\", \"look\", \"fit\", \"small\", \"light\", \"also\", \"11000\", \"presence\", \"snub\", \"zensah\", \"xxx\", \"strengths\", \"blocker\", \"vendedor\", \"greati\", \"louisville\", \"authenticity\", \"trials\", \"graduate\", \"leki\", \"mp5\", \"500lbs\", \"pantry\", \"nonstop\", \"devise\", \"sidewall\", \"thieve\", \"vis\", \"riden\", \"tusa\", \"wast\", \"tenkara\", \"centre\", \"s2\", \"automate\", \"vanity\", \"primos\", \"bdc\", \"excelente\", \"pedestrians\", \"en\", \"america\", \"wagon\", \"nose\", \"thank\", \"presta\", \"lock\", \"awesome\", \"kite\", \"scope\", \"great\", \"quality\", \"exercise\", \"line\", \"ring\", \"good\", \"fit\", \"easy\", \"tire\", \"use\", \"seem\", \"little\", \"laser\", \"fine\", \"pad\", \"get\", \"work\", \"yet\", \"want\", \"miles\", \"far\", \"happy\", \"case\", \"gun\", \"product\", \"best\", \"1\", \"enough\", \"hold\", \"look\", \"one\", \"light\", \"well\", \"put\", \"buy\", \"size\", \"make\", \"like\", \"keep\", \"price\", \"really\", \"small\", \"go\", \"bike\", \"would\", \"amd\", \"gymnastics\", \"dh\", \"razer\", \"fde\", \"stumpjumper\", \"serengeti\", \"pa\", \"enamel\", \"m2\", \"buts\", \"pastel\", \"m48\", \"hearty\", \"leotard\", \"gnomes\", \"grat\", \"930\", \"diablo\", \"madevery\", \"reconnect\", \"endanger\", \"partition\", \"shrader\", \"brutally\", \"pd35\", \"georgiadogscom\", \"richt\", \"apparantly\", \"pancake\", \"shank\", \"inhumane\", \"hydraulic\", \"monkey\", \"vanquisher\", \"stepper\", \"serfas\", \"emblem\", \"bag\", \"garment\", \"well\", \"trike\", \"crossbow\", \"tee\", \"dillon\", \"knife\", \"goggle\", \"bungie\", \"much\", \"love\", \"towel\", \"nassl\", \"keep\", \"need\", \"mini\", \"make\", \"class\", \"sheath\", \"expect\", \"ship\", \"image\", \"gift\", \"video\", \"stuff\", \"survival\", \"better\", \"work\", \"fit\", \"one\", \"extra\", \"great\", \"glass\", \"band\", \"around\", \"clip\", \"hand\", \"water\", \"best\", \"like\", \"perfect\", \"get\", \"use\", \"pretty\", \"good\", \"2\", \"say\", \"buy\", \"quality\", \"purchase\", \"bottle\", \"come\", \"take\", \"go\", \"would\", \"easy\", \"hold\", \"time\"], \"Freq\": [5174.0, 8953.0, 2455.0, 3106.0, 6142.0, 5820.0, 3273.0, 8413.0, 4671.0, 2899.0, 6278.0, 4587.0, 1488.0, 2308.0, 2029.0, 2681.0, 2920.0, 2210.0, 1945.0, 5306.0, 1249.0, 1119.0, 1835.0, 2590.0, 3140.0, 3098.0, 716.0, 2642.0, 1229.0, 960.0, 4.4825583876339525, 6.860204294309179, 4.409793218894582, 4.085617860440204, 8.064675998337151, 3.329192592400233, 3.3031840670795387, 3.298667469942563, 3.2942522241570042, 3.288235082850726, 3.2715583641749375, 3.424342125384121, 3.304470685074206, 3.263835935365286, 3.258420100063388, 3.2576926150275454, 3.416332307675317, 3.1118674063351177, 3.116004446062089, 4.804054397274694, 4.380087409878401, 4.6031219420382765, 2.9233477708056435, 4.71230863719343, 3.9914376272936933, 3.189678375912152, 3.8318776099582217, 3.0700212018820783, 3.166722294816184, 3.2871664722931673, 11.598558868395974, 8.543667926817559, 7.3113545304080265, 17.993661811052185, 8.15702000347594, 414.79783810683466, 17.102812000933383, 1887.05143601425, 1042.2185241658126, 897.8477930727322, 892.4285730438233, 242.34597512541845, 216.80891724562528, 322.5720154459015, 30.69895703061028, 80.09198989413092, 106.19402510061008, 420.7955308370075, 9.353723024386232, 10.06311514347497, 1717.6862263996095, 524.6700384320321, 659.1532745069102, 782.0573921269727, 1178.277758790597, 103.60356618363903, 1057.2777079230843, 977.4013719380358, 607.6363363273015, 306.02237640016085, 400.3184765882846, 259.8470598456379, 1725.7641222873078, 345.9196447010207, 1419.1243978004052, 1696.0229287254847, 628.8423149370992, 189.49954664928282, 582.3649414260952, 222.58167255501013, 829.8541779370366, 2253.0209192916686, 787.6741670263162, 567.9493564357925, 828.757569918912, 1451.654084017764, 882.904234202167, 1828.9203276870544, 1204.2224858163104, 1093.9248764576428, 759.8050866527199, 1281.272106762341, 694.9541524550318, 662.5181502573237, 767.6955274341836, 785.5622715052659, 686.0458556961258, 773.9313482254578, 895.5373849449869, 673.1529407594136, 5.512386259001349, 8.13260689167658, 5.968886766695575, 4.2850229225644325, 5.288272019025043, 4.425184263982809, 3.490011285587233, 3.4526711628600806, 3.3479623943468027, 3.4422666689595984, 3.7213346221458523, 6.680826687105092, 3.408183962224415, 7.3046771208388925, 3.293539572469525, 4.946193093257609, 3.6254810291820063, 2.700744702517772, 2.694553171583368, 2.617538037909876, 3.514060174847287, 21.459981740931525, 3.9964348158263316, 2.4556549431164085, 2.448150683586563, 2.4470601885722396, 2.4428900070061443, 4.446365938073555, 2.4439756209211407, 2.440849420364018, 77.88188368864725, 14.68008998462899, 7.977654957927284, 4.296803599351605, 4.215837646458238, 355.35612234136175, 1480.6660496446054, 488.01228313773726, 15.73512754494781, 160.50717606038728, 14.652425062138185, 870.5517322949518, 262.63331701951176, 19.590483946929293, 687.1558801661366, 1126.9199872028114, 933.0387711198664, 92.66946007443, 660.2973658178678, 1704.8610379341992, 722.4938448590397, 238.86691592765433, 363.6612221150275, 1077.5204137497537, 1011.1476799064296, 259.71415776541403, 1715.3773469095677, 456.25784010858496, 589.5230150937285, 1708.4472792316456, 573.8313166993564, 506.7922358488178, 1279.7420113407932, 131.06201442910736, 1132.0140816254025, 238.02732090367238, 310.7252795662107, 784.0622355237681, 661.198446614453, 739.5759376043544, 496.0695287270417, 1798.9744764937354, 1653.1224324957484, 728.7950891243844, 1065.3182994012159, 914.810169012847, 1019.920997697409, 975.2793131392825, 607.510010823525, 602.1000346223774, 700.5204541604853, 565.4198204453043, 6.145098468841817, 5.142063960204928, 4.3688527838500555, 6.177504816565082, 6.3953577640994235, 3.4021115676336544, 4.207133874035868, 3.3845676320047753, 3.3237648117353493, 3.1898000919791007, 4.123624037982517, 4.866244491263659, 3.9080920179083494, 3.27434160745028, 3.512856241736604, 5.851383600175853, 6.988872677262159, 5.271868244215379, 3.918829585557779, 3.19407643360593, 2.388957187739581, 2.3855237979747996, 2.3793674395423072, 2.3781360273638317, 2.378651632919451, 2.3740472425263075, 13.444958566729898, 2.3619700838761064, 3.7537074917538664, 2.3465848074739557, 11.71577675742265, 4.383622237086321, 6.298566284846323, 4.414602122936365, 3.6391243426857622, 5.945197586129564, 25.20388228351808, 4.340772652405458, 9.102337508213605, 12.401082572070182, 1172.0064610025463, 73.5998054862518, 189.00985848617734, 2816.9428145183765, 12.270811854696065, 1675.740227270625, 74.48992518804755, 195.394038708586, 876.2521321228268, 780.7531940440108, 355.2173371076631, 323.5306492338767, 88.8660533390286, 1456.6694915331254, 1367.3556172075444, 227.61922671056513, 74.97768336059771, 64.85871687174533, 148.43414207286867, 154.9312104086428, 98.73301093920303, 266.0050066366105, 445.1028601751056, 154.78978931136015, 585.4219009255829, 84.51308738793861, 1561.0148534911295, 263.4002928757869, 888.1209542837097, 366.3760716057675, 449.0238676204603, 276.56254037379665, 194.464139171807, 376.71280440543507, 930.2280257535007, 889.3397203110281, 814.3103209170806, 629.6341191646733, 601.7525984181325, 487.85629963980966, 508.2947877245329, 308.01212274782614, 522.432941198726, 372.30919390647324, 361.27933738194423, 641.9384289897539, 448.7201951487706, 359.27468546041183, 418.41397020170706, 429.2422675698885, 502.91206428585934, 433.2649986995025, 470.29841409422664, 391.3551105292819, 393.37801516846713, 379.9313369799387, 4.125362248977611, 3.925099212530925, 3.8410292649669633, 4.011445954823545, 4.689148061012207, 3.6965461044198706, 4.75426000413238, 3.0681268350224378, 3.0474889468322672, 3.0340813771735773, 3.1394884002406167, 2.986947539539983, 2.90499688514289, 2.9370392819901014, 3.8666318416276275, 2.7792394640782128, 3.0504079093210836, 2.919942985880481, 3.9371945350001205, 4.859350628492381, 4.693200436638714, 2.8986206636882543, 2.2887381318990894, 2.2900547652080263, 2.2900111033826693, 2.268755569827404, 2.2649322692572227, 2.1513672633966676, 2.150889375746528, 3.61186050518147, 5.904384256897351, 7.797671853574012, 8.71240743044625, 5.111012604992116, 5.954671515040856, 10.125168528031724, 4.48426843448349, 60.00374720133828, 173.77631699352088, 21.22368554325684, 225.2264869216556, 247.60696282175337, 14.62408620271419, 237.7436743335693, 1868.9985431675113, 689.7347948722233, 113.28760214778707, 211.76618494260205, 137.7894414631296, 1252.597827984367, 1040.428107293458, 626.6834889448799, 179.02906983945616, 1679.502463410315, 414.5789443939301, 606.941345231873, 67.44153396729453, 255.6778564225764, 200.7800243579621, 1155.023685347879, 1114.2789516004602, 194.19182414311172, 431.58379230560865, 105.12237029504763, 266.5085793139932, 216.2767106817575, 271.11546570486604, 244.83679823880115, 594.4359987475009, 272.9410611239761, 247.04051224278854, 341.20701967135074, 434.2586170064591, 562.4501318026131, 815.5150987207687, 488.8840311798967, 705.3339409461897, 370.1700815534128, 572.2025647105376, 439.5383947279687, 547.5114747084534, 566.5814416295544, 375.2892666951402, 399.6364849329521, 376.6581697882082, 349.4951330463842, 368.57007621936145, 311.30686576288116, 344.91930357106753, 5.878949495194015, 3.700696043912823, 3.2971162784905568, 3.2850046186017288, 3.144453473168384, 3.125489690777119, 3.1239955988705552, 6.836775591023436, 4.258098831277442, 3.679901957201606, 2.214256892788298, 2.2134632712325657, 2.209275139640178, 2.2058647705274192, 3.9605091110185895, 2.199123995432991, 2.307020134606365, 2.200197905291642, 2.189481343286965, 2.202167769481301, 2.1776281028697975, 2.177952295772875, 2.1415772510720252, 2.1606670713839002, 2.1180826141069002, 2.0974070531223497, 2.0208759930400064, 2.0184422091399177, 2.0177173658931804, 7.10550847028021, 3.872517948668795, 3.753448339161329, 4.066364938316878, 5.863531802219423, 6.370185546053834, 8.975319585118672, 5.137602793050718, 5.516354590551688, 772.1628301659624, 8.716562231668448, 1355.8608498114295, 9.89160091131289, 22.85959949291901, 51.32819161497538, 6.696882513779552, 398.81012992109066, 87.91695923514693, 4.392191493170995, 545.7101703412272, 715.8090409002592, 114.77835318762222, 38.19343902158529, 494.624153161978, 604.1383240902254, 57.67225475862261, 851.5182654974257, 118.88468800584842, 99.16632342833707, 290.21760435938853, 162.70195707429795, 104.50925751926158, 114.20199362924734, 95.11301334759305, 157.20117743198074, 37.84762969696587, 368.9287939382472, 925.8805932500296, 742.8010361807584, 799.0098648101209, 163.8374856203024, 1077.1127429700514, 93.47161833567948, 131.37594005627318, 271.0094012194703, 139.46837185359107, 253.92178158649165, 336.01501563431344, 222.72101320789943, 628.1465747634048, 318.1628696735591, 677.4770382928205, 829.5209162931055, 221.48581354040167, 589.8579492331729, 271.78615005372995, 277.2947397067462, 467.8476329783035, 355.8721013868135, 275.8539155988732, 229.00998425829118, 295.0576314549424, 290.9961053711511, 320.2439437146092, 334.56504601459585, 288.9928750208717, 272.8969878545558, 272.9451086318316], \"Total\": [5174.0, 8953.0, 2455.0, 3106.0, 6142.0, 5820.0, 3273.0, 8413.0, 4671.0, 2899.0, 6278.0, 4587.0, 1488.0, 2308.0, 2029.0, 2681.0, 2920.0, 2210.0, 1945.0, 5306.0, 1249.0, 1119.0, 1835.0, 2590.0, 3140.0, 3098.0, 716.0, 2642.0, 1229.0, 960.0, 5.26065160984984, 8.051625567437881, 5.204210946898867, 4.874385540845122, 9.927519249535882, 4.107753718254465, 4.084927785987983, 4.081227721849694, 4.083049999874272, 4.080917064993989, 4.062132862313551, 4.253440066897271, 4.10468095118799, 4.056583834917511, 4.05218350926795, 4.052187130366116, 4.25123107011344, 3.8929718316440565, 3.9009194754105447, 6.044185853810616, 5.528262961130577, 5.817346788420744, 3.7024775938830463, 5.972187611456708, 5.067803890138312, 4.0752727487724245, 4.901089996207948, 3.963495955711787, 4.088681429912433, 4.2523809636075045, 15.73886699159338, 11.529854529005872, 9.81904361066502, 25.4941831953112, 11.127167438345829, 789.524694626997, 24.866900945972134, 4201.461931511175, 2201.09505967457, 1932.3520682156698, 1945.3880442483517, 463.7679068666052, 416.04039033460936, 659.3247083984006, 48.39048516525083, 141.1021687721425, 193.64313890552756, 912.1552242905842, 13.029123338023838, 14.182736144515665, 4671.734238128538, 1217.154297623006, 1593.8932980815198, 1953.5785350397134, 3140.3494903023766, 199.4885863514593, 2803.093034093223, 2566.7173282651447, 1511.1087526982417, 689.559761007446, 939.2494343784276, 581.5909486213304, 5267.29160560422, 815.5580553612352, 4262.105718785803, 5306.094217411091, 1655.3177720302485, 405.57231191540416, 1560.2881202282297, 499.4625154085942, 2455.3171612917745, 8413.26949141611, 2333.088476937277, 1575.7822555925904, 2834.026310895914, 6142.833169278162, 3106.3243975055575, 8953.860998402586, 5174.677994582366, 4587.006948921396, 2642.367870663996, 6278.889601167812, 2284.257089617491, 2117.43684578172, 2920.1525146924773, 3087.2765697637988, 2304.612947411271, 3098.902667437125, 5820.726126279639, 3273.788011863222, 6.297413787570794, 9.403670575468993, 6.961046264535747, 5.060648593146187, 6.259270837627153, 5.25930672263307, 4.257136332958029, 4.229655699712659, 4.113508258914467, 4.233310557958123, 4.58315690219891, 8.248837851231722, 4.245742481547726, 9.115127117987189, 4.110309981762997, 6.187417878374344, 4.564546521694438, 3.4664785305725396, 3.465235824219308, 3.382754386202995, 4.569160183576923, 27.964526779548034, 5.234272352847332, 3.2206049033544613, 3.2147481506505993, 3.2145127783386105, 3.2107511612054536, 5.847178234078048, 3.214804443041336, 3.2118977274241733, 111.05064808143906, 20.18951496571889, 10.780718835392836, 5.7480303812868865, 5.646103483937899, 607.9849781871208, 2899.3302197402586, 960.6641015229836, 23.277139918841026, 298.80890504624153, 22.008806657131192, 2029.7096147902423, 536.0869981650978, 30.604748671450558, 1739.0233852702552, 3098.902667437125, 2574.6798930739897, 181.87578001454264, 1750.334179304841, 5267.29160560422, 1975.3631406412314, 553.6067401923395, 919.4282887672108, 3273.788011863222, 3087.2765697637988, 629.4622411278177, 5820.726126279639, 1229.815132694155, 1722.3114353397082, 6278.889601167812, 1705.892504318942, 1488.4154573124022, 4587.006948921396, 293.3915304627472, 4201.461931511175, 613.067484009554, 868.3010243201368, 2803.093034093223, 2284.257089617491, 2642.367870663996, 1600.8974812903537, 8953.860998402586, 8413.26949141611, 2920.1525146924773, 5306.094217411091, 4262.105718785803, 5174.677994582366, 6142.833169278162, 2590.997040138186, 2834.026310895914, 4671.734238128538, 2681.828002163513, 6.996777049006107, 5.933611713575322, 5.16103098710971, 7.35179975865108, 7.802291201617291, 4.174648644995863, 5.17406020915069, 4.174075978608636, 4.113087492320983, 3.968314646497127, 5.162547421677154, 6.135775162661305, 4.939305127061049, 4.171603269502445, 4.495224094539445, 7.505490045665707, 9.031489643922725, 6.839747318794764, 5.110248117823502, 4.217471811374228, 3.15967536156674, 3.1579444160592596, 3.1528647721433396, 3.1516339943982454, 3.1524258934649203, 3.1483852157497205, 17.83993577120037, 3.138303959210007, 4.993533266524841, 3.1290310097313188, 15.689742063158585, 5.914626077864337, 8.6079645436287, 5.981601797473518, 4.899015759096897, 8.243366917257138, 37.72731931261541, 5.9507828120484785, 13.10491340040235, 18.621646991636425, 3106.3243975055575, 138.55645590482482, 411.64597795331446, 8953.860998402586, 19.109508049259755, 6142.833169278162, 162.16619435296448, 518.4235480557921, 3140.3494903023766, 2834.026310895914, 1110.0424734758408, 994.5312208577235, 209.9740090268198, 6278.889601167812, 5820.726126279639, 664.3444082883693, 172.01731344529657, 144.28742612073313, 399.75867774951973, 425.7898078169145, 244.68811582551066, 832.9888953603524, 1607.820520341801, 433.62123415349964, 2304.612947411271, 204.32172263511774, 8413.26949141611, 877.6452198923957, 4262.105718785803, 1360.7684149674174, 1800.4821941588023, 957.4847232933779, 607.4172184364542, 1506.2086696021383, 5306.094217411091, 5174.677994582366, 4587.006948921396, 3273.788011863222, 3087.2765697637988, 2333.088476937277, 2681.828002163513, 1249.042818354763, 2920.1525146924773, 1705.892504318942, 1660.0659109145424, 5267.29160560422, 2590.997040138186, 1655.3177720302485, 2308.7469871853036, 2574.6798930739897, 4201.461931511175, 3098.902667437125, 4671.734238128538, 2117.43684578172, 2566.7173282651447, 2284.257089617491, 4.917401898037617, 4.732742875362069, 4.6651601892317585, 4.875442099753469, 5.706012901016108, 4.5124041550229075, 5.84652594885937, 3.8588615818319525, 3.8431107919020224, 3.832923357759519, 4.00053207080126, 3.8398193657590842, 3.7375286878146112, 3.781656598748896, 5.070459683429188, 3.6473834193262626, 4.004314256304208, 3.8466195739936824, 5.238896093872666, 6.491779729942598, 6.2879694731709606, 3.883658804404912, 3.081992531784436, 3.0840917178873855, 3.0844761007552335, 3.085646478277408, 3.087426417082188, 2.9421223450068203, 2.9421842779629594, 4.941607506456344, 8.37000987207863, 11.521957999660206, 12.986217884185587, 7.437112230290688, 8.89434692551273, 16.201034092380358, 6.512510093721897, 123.63349812993022, 461.29648962751247, 39.420176916969446, 643.8754324007862, 727.8590440483104, 25.71341977726791, 716.3772194521285, 8413.26949141611, 2681.828002163513, 304.4514193817778, 649.5622968773341, 392.5316660842299, 5820.726126279639, 4671.734238128538, 2590.997040138186, 563.3463017811011, 8953.860998402586, 1622.471281783113, 2642.367870663996, 170.87651391486355, 912.607366381302, 684.5504913243225, 6278.889601167812, 6142.833169278162, 674.632744873133, 1881.0869635192773, 311.0924523123572, 1054.0653516860386, 812.1250091931486, 1098.9884914220231, 962.9243965588245, 3106.3243975055575, 1119.5891678365826, 980.1944435952057, 1523.9549486702203, 2145.0137346492465, 3098.902667437125, 5306.094217411091, 2566.7173282651447, 5174.677994582366, 1932.3520682156698, 4262.105718785803, 2803.093034093223, 4587.006948921396, 5267.29160560422, 2210.780706845528, 2834.026310895914, 2574.6798930739897, 2117.43684578172, 3087.2765697637988, 2201.09505967457, 4201.461931511175, 6.689666852935562, 4.539959361363502, 4.085687133474331, 4.083515684565323, 3.9340800142592767, 3.9193672836541236, 3.918935170515376, 8.831833287970687, 5.658343126117281, 4.912615608920651, 3.000294987785919, 2.9996703562551463, 2.9970915906075586, 2.9973096363882785, 5.382520870015959, 2.9892501133317264, 3.1393032677502357, 2.994012208034727, 2.9804733907327576, 3.000142085797142, 2.97233853255991, 2.9731203791708207, 2.9459729055635515, 2.9797197291521593, 2.928548550593635, 2.913874914665946, 2.8077958345295277, 2.805925290119779, 2.8052529848967596, 10.022813949230287, 5.491710131739561, 5.364743349403208, 5.857447045183025, 8.658651911380437, 9.49712179559885, 14.014609586523079, 7.715724815978021, 8.406954746651738, 2455.3171612917745, 14.434456179700636, 5174.677994582366, 17.26201080220757, 47.07839468974488, 123.80027320768293, 11.105142300843717, 1488.4154573124022, 248.3887548844031, 6.8107367611202925, 2308.7469871853036, 3273.788011863222, 353.3662233309616, 92.89710685256716, 2210.780706845528, 2920.1525146924773, 156.92777427444506, 4587.006948921396, 388.8340585185376, 311.2344636405013, 1249.042818354763, 598.0776269565762, 341.68398072540555, 386.11078872731395, 307.26300274511027, 591.4980207890665, 95.0564011467821, 1835.1657999738784, 6142.833169278162, 4671.734238128538, 5306.094217411091, 653.9164573772159, 8413.26949141611, 314.7303703239287, 507.50213006411997, 1394.7051557186114, 559.3837046513338, 1313.7828987322837, 2029.7096147902423, 1119.5891678365826, 5267.29160560422, 1945.3880442483517, 6278.889601167812, 8953.860998402586, 1140.4890550460193, 5820.726126279639, 1600.8974812903537, 1660.0659109145424, 4262.105718785803, 2681.828002163513, 1722.3114353397082, 1229.815132694155, 2304.612947411271, 2333.088476937277, 3087.2765697637988, 4201.461931511175, 2590.997040138186, 2145.0137346492465, 3140.3494903023766], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -10.6385, -10.213, -10.6549, -10.7313, -10.0512, -10.936, -10.9438, -10.9452, -10.9466, -10.9484, -10.9535, -10.9078, -10.9435, -10.9558, -10.9575, -10.9577, -10.9102, -11.0035, -11.0022, -10.5693, -10.6617, -10.612, -11.066, -10.5886, -10.7546, -10.9788, -10.7954, -11.017, -10.986, -10.9487, -9.6878, -9.9935, -10.1493, -9.2487, -10.0399, -6.1109, -9.2995, -4.596, -5.1896, -5.3387, -5.3448, -6.6484, -6.7597, -6.3624, -8.7145, -7.7556, -7.4735, -6.0966, -9.903, -9.8299, -4.69, -5.876, -5.6478, -5.4768, -5.0669, -7.4982, -5.1753, -5.2538, -5.7292, -6.4151, -6.1465, -6.5786, -4.6853, -6.2925, -4.8809, -4.7027, -5.6948, -6.8943, -5.7716, -6.7334, -5.4175, -4.4187, -5.4696, -5.7967, -5.4188, -4.8583, -5.3555, -4.6272, -5.0451, -5.1412, -5.5057, -4.9831, -5.5949, -5.6427, -5.4953, -5.4723, -5.6078, -5.4872, -5.3413, -5.6268, -10.2624, -9.8735, -10.1828, -10.5143, -10.3039, -10.4821, -10.7195, -10.7302, -10.761, -10.7333, -10.6553, -10.0701, -10.7432, -9.9809, -10.7774, -10.3708, -10.6814, -10.9759, -10.9782, -11.0072, -10.7126, -8.9032, -10.584, -11.071, -11.0741, -11.0745, -11.0762, -10.4773, -11.0758, -11.077, -7.6142, -9.2829, -9.8927, -10.5115, -10.5305, -6.0963, -4.6691, -5.779, -9.2135, -6.891, -9.2848, -5.2003, -6.3986, -8.9943, -5.4368, -4.9421, -5.1309, -7.4403, -5.4767, -4.5281, -5.3867, -6.4935, -6.0732, -4.987, -5.0505, -6.4098, -4.522, -5.8463, -5.5901, -4.526, -5.6171, -5.7413, -4.815, -7.0937, -4.9376, -6.497, -6.2305, -5.3049, -5.4753, -5.3633, -5.7627, -4.4744, -4.559, -5.378, -4.9984, -5.1507, -5.0419, -5.0867, -5.56, -5.569, -5.4176, -5.6318, -9.9498, -10.128, -10.2909, -9.9445, -9.9099, -10.5411, -10.3287, -10.5462, -10.5644, -10.6055, -10.3487, -10.1831, -10.4024, -10.5793, -10.509, -9.9988, -9.8211, -10.1031, -10.3997, -10.6042, -10.8946, -10.896, -10.8986, -10.8991, -10.8989, -10.9009, -9.1668, -10.906, -10.4427, -10.9125, -9.3045, -10.2876, -9.9251, -10.2805, -10.4737, -9.9829, -8.5385, -10.2974, -9.5569, -9.2477, -4.699, -7.4668, -6.5237, -3.822, -9.2582, -4.3414, -7.4548, -6.4904, -4.9898, -5.1052, -5.8927, -5.9862, -7.2783, -4.4815, -4.5448, -6.3378, -7.4483, -7.5932, -6.7653, -6.7225, -7.173, -6.1819, -5.6671, -6.7234, -5.3931, -7.3285, -4.4124, -6.1918, -4.9763, -5.8618, -5.6584, -6.143, -6.4952, -5.834, -4.93, -4.975, -5.0631, -5.3203, -5.3656, -5.5754, -5.5344, -6.0353, -5.507, -5.8457, -5.8758, -5.301, -5.6591, -5.8814, -5.729, -5.7034, -5.545, -5.6941, -5.6121, -5.7958, -5.7907, -5.8255, -10.1875, -10.2372, -10.2589, -10.2155, -10.0594, -10.2972, -10.0456, -10.4836, -10.4903, -10.4947, -10.4606, -10.5104, -10.5382, -10.5272, -10.2522, -10.5825, -10.4894, -10.5331, -10.2342, -10.0237, -10.0585, -10.5404, -10.7766, -10.7761, -10.7761, -10.7854, -10.7871, -10.8385, -10.8388, -10.3204, -9.8289, -9.5508, -9.4399, -9.9732, -9.8205, -9.2896, -10.1041, -7.5102, -6.4469, -8.5495, -6.1875, -6.0928, -8.922, -6.1334, -4.0715, -5.0683, -6.8747, -6.2491, -6.6789, -4.4717, -4.6572, -5.1642, -6.4171, -4.1784, -5.5774, -5.1962, -7.3934, -6.0607, -6.3024, -4.5528, -4.5887, -6.3358, -5.5372, -6.9495, -6.0192, -6.2281, -6.0021, -6.104, -5.217, -5.9954, -6.0951, -5.7721, -5.531, -5.2723, -4.9008, -5.4125, -5.046, -5.6907, -5.2551, -5.5189, -5.2992, -5.265, -5.6769, -5.6141, -5.6733, -5.7481, -5.695, -5.8639, -5.7613, -9.6557, -10.1186, -10.234, -10.2377, -10.2815, -10.2875, -10.288, -9.5048, -9.9783, -10.1242, -10.6322, -10.6325, -10.6344, -10.636, -10.0507, -10.639, -10.5911, -10.6385, -10.6434, -10.6377, -10.6489, -10.6487, -10.6656, -10.6567, -10.6766, -10.6864, -10.7236, -10.7248, -10.7251, -9.4662, -10.0732, -10.1044, -10.0243, -9.6583, -9.5755, -9.2326, -9.7905, -9.7194, -4.7779, -9.2619, -4.2149, -9.1354, -8.2977, -7.4889, -9.5255, -5.4386, -6.9507, -9.9473, -5.125, -4.8537, -6.6841, -7.7844, -5.2233, -5.0233, -7.3723, -4.6801, -6.6489, -6.8303, -5.7565, -6.3352, -6.7778, -6.6891, -6.872, -6.3696, -7.7935, -5.5165, -4.5963, -4.8167, -4.7437, -6.3282, -4.4451, -6.8894, -6.549, -5.8249, -6.4893, -5.8901, -5.6099, -6.0212, -4.9843, -5.6645, -4.9087, -4.7062, -6.0267, -5.0472, -5.8221, -5.802, -5.279, -5.5525, -5.8072, -5.9933, -5.7399, -5.7538, -5.658, -5.6143, -5.7607, -5.818, -5.8178], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.1236, 1.1235, 1.118, 1.1071, 1.0758, 1.0735, 1.0712, 1.0708, 1.069, 1.0677, 1.0672, 1.0668, 1.0668, 1.0662, 1.0656, 1.0654, 1.065, 1.0597, 1.059, 1.054, 1.0508, 1.0495, 1.0474, 1.0467, 1.0449, 1.0386, 1.0375, 1.0282, 1.0281, 1.0262, 0.9784, 0.9839, 0.9887, 0.9352, 0.9731, 0.64, 0.9093, 0.4832, 0.536, 0.5171, 0.5044, 0.6346, 0.6319, 0.5687, 0.8286, 0.7173, 0.6829, 0.51, 0.9522, 0.9405, 0.2831, 0.4421, 0.4007, 0.3681, 0.3034, 0.6284, 0.3086, 0.3181, 0.3726, 0.4712, 0.4308, 0.478, 0.1678, 0.426, 0.1839, 0.1431, 0.3158, 0.5227, 0.2981, 0.4754, 0.1989, -0.0339, 0.1978, 0.2632, 0.0541, -0.1589, 0.0257, -0.3047, -0.1743, -0.1498, 0.0373, -0.3057, 0.0937, 0.1217, -0.0524, -0.085, 0.0719, -0.1037, -0.5881, -0.2981, 1.3198, 1.3078, 1.2992, 1.2866, 1.2844, 1.2803, 1.2543, 1.25, 1.2471, 1.2461, 1.2447, 1.2421, 1.2332, 1.2316, 1.2314, 1.2291, 1.2226, 1.2034, 1.2014, 1.1965, 1.1904, 1.1882, 1.1832, 1.1818, 1.1806, 1.1802, 1.1797, 1.1791, 1.1788, 1.1785, 1.0982, 1.1343, 1.1519, 1.162, 1.1609, 0.9159, 0.781, 0.7757, 1.0614, 0.8315, 1.0461, 0.6065, 0.7394, 1.0069, 0.5245, 0.4414, 0.4379, 0.7787, 0.4781, 0.3249, 0.4472, 0.6124, 0.5254, 0.3417, 0.3368, 0.5677, 0.2312, 0.4614, 0.3809, 0.1514, 0.3635, 0.3756, 0.1764, 0.6471, 0.1415, 0.5069, 0.4253, 0.179, 0.2132, 0.1796, 0.2814, -0.1519, -0.1742, 0.065, -0.1526, -0.0858, -0.1711, -0.3873, 0.0025, -0.0961, -0.4445, -0.1037, 1.5271, 1.5137, 1.4903, 1.4829, 1.4581, 1.4523, 1.45, 1.4472, 1.4438, 1.4385, 1.4322, 1.4251, 1.4227, 1.4147, 1.4103, 1.408, 1.4005, 1.3965, 1.3915, 1.379, 1.3773, 1.3764, 1.3754, 1.3753, 1.3753, 1.3746, 1.3741, 1.3727, 1.3715, 1.3692, 1.3648, 1.3574, 1.3445, 1.3531, 1.3596, 1.3301, 1.2535, 1.3414, 1.2925, 1.2504, 0.6822, 1.0243, 0.8785, 0.5005, 1.214, 0.3579, 0.879, 0.6811, 0.3805, 0.3677, 0.5175, 0.5339, 0.7971, 0.1959, 0.2084, 0.5858, 0.8265, 0.8573, 0.6662, 0.6459, 0.7493, 0.5154, 0.3726, 0.6268, 0.2866, 0.7741, -0.0276, 0.4533, 0.0885, 0.3448, 0.2682, 0.415, 0.5179, 0.271, -0.0843, -0.1041, -0.0717, 0.0083, 0.0217, 0.092, -0.0063, 0.2569, -0.064, 0.1348, 0.132, -0.4479, -0.0965, 0.1293, -0.0511, -0.1345, -0.4659, -0.3105, -0.639, -0.0314, -0.2187, -0.1369, 1.6421, 1.6306, 1.6233, 1.6227, 1.6215, 1.6183, 1.6109, 1.5884, 1.5858, 1.584, 1.5754, 1.5666, 1.5657, 1.565, 1.5467, 1.5459, 1.5456, 1.5421, 1.5321, 1.5281, 1.5252, 1.5252, 1.5202, 1.52, 1.5199, 1.5102, 1.5079, 1.5047, 1.5045, 1.5043, 1.4688, 1.4273, 1.4186, 1.4426, 1.4165, 1.3477, 1.4446, 1.0948, 0.8415, 1.1986, 0.7673, 0.7395, 1.2534, 0.7147, 0.3133, 0.4598, 0.8291, 0.6969, 0.7708, 0.2815, 0.3158, 0.3984, 0.6714, 0.1441, 0.4533, 0.3467, 0.8881, 0.5453, 0.5912, 0.1247, 0.1107, 0.5724, 0.3456, 0.7328, 0.4427, 0.4946, 0.4181, 0.4483, 0.1641, 0.4063, 0.4395, 0.3212, 0.2205, 0.1112, -0.0551, 0.1595, -0.1751, 0.1652, -0.1903, -0.035, -0.3079, -0.4119, 0.0443, -0.1412, -0.1044, 0.0163, -0.3077, -0.1382, -0.6821, 1.8661, 1.7909, 1.7808, 1.7777, 1.7712, 1.7689, 1.7686, 1.7392, 1.711, 1.7063, 1.6915, 1.6913, 1.6903, 1.6887, 1.6885, 1.6883, 1.6872, 1.6872, 1.6869, 1.6861, 1.6842, 1.684, 1.6764, 1.6739, 1.6713, 1.6665, 1.6664, 1.6659, 1.6657, 1.6513, 1.6459, 1.6381, 1.6303, 1.6055, 1.5959, 1.5496, 1.5886, 1.5739, 0.8385, 1.4909, 0.6559, 1.4384, 1.2728, 1.1148, 1.4895, 0.6783, 0.9567, 1.5566, 0.5529, 0.475, 0.8708, 1.1064, 0.498, 0.4197, 0.9943, 0.3113, 0.8103, 0.8515, 0.5358, 0.6935, 0.8107, 0.7771, 0.8226, 0.6701, 1.0744, 0.391, 0.103, 0.1564, 0.102, 0.6112, -0.0603, 0.7812, 0.6438, 0.357, 0.6063, 0.3516, 0.1968, 0.3805, -0.1312, 0.1846, -0.2313, -0.3837, 0.3564, -0.294, 0.222, 0.2057, -0.2141, -0.0244, 0.1637, 0.3144, -0.0602, -0.0864, -0.2707, -0.5351, -0.1981, -0.0665, -0.4476]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 1, 3, 4, 5, 4, 1, 4, 1, 2, 3, 4, 5, 3, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 3, 1, 2, 3, 2, 2, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 1, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 2, 1, 2, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 2, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 3, 1, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 1, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 1, 1, 4, 5, 5, 4, 5, 1, 3, 1, 2, 3, 4, 5, 3, 1, 3, 1, 3, 4, 5, 3, 4, 2, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 4, 5, 1, 3, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 1, 1, 2, 3, 4, 5, 1, 5, 3, 1, 2, 3, 4, 5, 3, 4, 5, 1, 1, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 2, 4, 2, 2, 1, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 5, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 2, 4, 5, 3, 4, 1, 2, 3, 4, 5, 1, 2, 5, 4, 1, 4, 5, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 3, 4, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 5, 1, 5, 4, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 3, 4, 3, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 3, 5, 1, 2, 3, 4, 5, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 5, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 2, 4, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 2, 3, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 3, 2, 3, 4, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 3, 5, 1, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 4, 3, 4, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 2, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 1, 1, 2, 3, 4, 5, 4, 2, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5], \"Freq\": [0.18057641640039362, 0.2356675264886493, 0.18465723936989403, 0.251990818366651, 0.14588942115964004, 0.12130965539172381, 0.7278579323503428, 0.12130965539172381, 0.12130965539172381, 0.8134376817148659, 0.7235545827186857, 0.18088864567967142, 0.17802514110415404, 0.30982621048301895, 0.1811483891937006, 0.1611596014206026, 0.16990469607133296, 0.6333233700470773, 0.11617148222806788, 0.6970288933684073, 0.11617148222806788, 0.11617148222806788, 0.7624437010878594, 0.06353697509065495, 0.06353697509065495, 0.1270739501813099, 0.06353697509065495, 0.7303261601756422, 0.8727608688414916, 0.8225074402937748, 0.8010360172855577, 0.7361470470666475, 0.7065901931259835, 0.719147964508575, 0.6221327165536252, 0.6226848329955786, 0.66799994824096, 0.7092775897110974, 0.19434175064154993, 0.09717087532077497, 0.45913238589066174, 0.19677102252456932, 0.05344398142642623, 0.27969408516218724, 0.10994870933961844, 0.3761403214250104, 0.1388825802184654, 0.09451731153756672, 0.8575376859910522, 0.3042564705868466, 0.28937198137828146, 0.16635605586043412, 0.13483596106582554, 0.10506698264869523, 0.8969056504461171, 0.06172445501304872, 0.18517336503914616, 0.12344891002609744, 0.6172445501304872, 0.7056779437585236, 0.7129481764275193, 0.8206162533681075, 0.2029102702027271, 0.26457204842687737, 0.1598904249300641, 0.1785323578815514, 0.1943063011481945, 0.11088977349011639, 0.2633632120390264, 0.45048970480359785, 0.06930610843132275, 0.10395916264698411, 0.7499002499932803, 0.6797670747478514, 0.19234493429019994, 0.13051977683977853, 0.2459267374138985, 0.3407253121712113, 0.09067689759395141, 0.4002910484395259, 0.17199206173360704, 0.16431384469192817, 0.13104157084465298, 0.13257721425298877, 0.3380418681077137, 0.16535541982136356, 0.13603130596141733, 0.04602256758574897, 0.31441966527609033, 0.12898752490554052, 0.35817071647877774, 0.27870518774232866, 0.14395929118921935, 0.09098227203158663, 0.33891483367423264, 0.14187132572409739, 0.13793045556509467, 0.12216697492908386, 0.2581269954146772, 0.7050825664458905, 0.1410165132891781, 0.1410165132891781, 0.11706370223491575, 0.7023822134094945, 0.08104410154724936, 0.03601960068766638, 0.06303430120341617, 0.6210013522356856, 0.31236069431043945, 0.13386886899018835, 0.3640293805873543, 0.10568594920278027, 0.08220018271327355, 0.08679080413498218, 0.08679080413498218, 0.17358160826996435, 0.6943264330798574, 0.23002938402165707, 0.15172150861002914, 0.41601058812427344, 0.11256757090421517, 0.09299060205130817, 0.44376139285293326, 0.2479843077707568, 0.08701203781430063, 0.09716344222596904, 0.12326705357025923, 0.22150982442891815, 0.1205799447496127, 0.21525753099745676, 0.24383944382699457, 0.19918020503084172, 0.2800836850857379, 0.2691854872224796, 0.10135324012830203, 0.14876040083347558, 0.20107175057711532, 0.4734007263430316, 0.2462410687887938, 0.06678493932094591, 0.1412933069987359, 0.07178245178713914, 0.40235356913547937, 0.21772092803548143, 0.16147084024515948, 0.10058839228386984, 0.11845606722903093, 0.8552087245889118, 0.7337328797622296, 0.22279771383179228, 0.3707874361580193, 0.07968677356027608, 0.13985841890170903, 0.18620684842146143, 0.6391755127322098, 0.2857496519597159, 0.10001237818590056, 0.42386198374024525, 0.05714993039194318, 0.13334983758120075, 0.20931988357256262, 0.052329970893140655, 0.6279596507176878, 0.052329970893140655, 0.10465994178628131, 0.682932164329182, 0.7298719593681929, 0.1468269931835555, 0.1468269931835555, 0.587307972734222, 0.6666011202704801, 0.33293402220070867, 0.21468261473830053, 0.20834771790995724, 0.13420596243749497, 0.10980487835795043, 0.42424938080802377, 0.18637545052838037, 0.1385554336164933, 0.07479541106731054, 0.17656621629004457, 0.8272412730074641, 0.1718424176658539, 0.6873696706634156, 0.042960604416463474, 0.042960604416463474, 0.042960604416463474, 0.2556896657183401, 0.2183826326419987, 0.11192109922902432, 0.24659038935825686, 0.16833661266154065, 0.7603620799580332, 0.6477887177923825, 0.8754343991653711, 0.8868512630523491, 0.842657093412543, 0.23146120569504913, 0.14659209694019779, 0.14916388811458722, 0.16459463516092385, 0.30604314975234276, 0.4615442512291993, 0.15567525813431424, 0.14142329788258123, 0.10963046347486918, 0.13046025153509433, 0.20200802965905731, 0.252063116654222, 0.1483775793070952, 0.14658989762869645, 0.2484877532974245, 0.5669650629480206, 0.19135070874495694, 0.10630594930275386, 0.07087063286850258, 0.06378356958165232, 0.2642946741673781, 0.39589819504907664, 0.06525794423885879, 0.1337787856896605, 0.14139221251752737, 0.2976638661908808, 0.19005360552712217, 0.25383871971088234, 0.1301737024158371, 0.12800414070890648, 0.4134530214746504, 0.29048368580085454, 0.12234194110403161, 0.10979404970874632, 0.06336685154619073, 0.7347448598700427, 0.8693896581963734, 0.1241985225994819, 0.13602111494172164, 0.8161266896503299, 0.09275819314729038, 0.742065545178323, 0.09275819314729038, 0.10620583035914674, 0.02124116607182935, 0.2548939928619522, 0.1274469964309761, 0.488546819652075, 0.735128882116701, 0.7086652299487821, 0.7350729252226925, 0.09802400379776785, 0.6534933586517857, 0.06534933586517856, 0.06534933586517856, 0.16337333966294643, 0.8619393941637821, 0.2288200731677031, 0.1639576902225274, 0.31980758257690783, 0.13332823160952778, 0.15314729306499814, 0.7605565164675167, 0.049530659934028436, 0.7429598990104265, 0.09906131986805687, 0.049530659934028436, 0.049530659934028436, 0.1162673663448431, 0.19765452278623327, 0.4360026237931616, 0.10464062971035878, 0.15114757624829603, 0.9527720747590385, 0.7403409328060694, 0.7706194983519976, 0.1908799071563158, 0.7635196286252632, 0.7342706139735424, 0.6710343417990705, 0.27014512004696006, 0.6303386134429068, 0.1462042314417268, 0.731021157208634, 0.2389041710240575, 0.2346587011027899, 0.17329236314992216, 0.24199178551225212, 0.11154007338603007, 0.6329764204029779, 0.16804511802637326, 0.672180472105493, 0.11894913558304483, 0.11894913558304483, 0.11894913558304483, 0.713694813498269, 0.22486192822804768, 0.674585784684143, 0.1767301801448357, 0.7069207205793429, 0.17433012398649952, 0.23699781561563335, 0.2996655072447672, 0.15040245990992118, 0.13786892158409442, 0.6726939191603751, 0.20210571202826966, 0.2572254516723432, 0.19160671400082707, 0.22375989545986996, 0.12467560157588062, 0.32435755371235364, 0.1627341836262322, 0.24937763975487462, 0.1532922685352904, 0.1105259472410246, 0.1274718215219256, 0.0637359107609628, 0.7648309291315537, 0.0637359107609628, 0.07700471445329624, 0.07700471445329624, 0.6930424300796661, 0.15400942890659247, 0.1281674798029476, 0.7690048788176856, 0.7053114544501835, 0.2956136653353594, 0.09853788844511979, 0.14123764010467169, 0.37115937980995123, 0.0919686958821118, 0.228174723725966, 0.2153649146746837, 0.2465888242371843, 0.07765946737339896, 0.2321777890544917, 0.2553843050071226, 0.2416210789887747, 0.11928129215901535, 0.13304451817736326, 0.2507965630010066, 0.16222903041682907, 0.2523562695372897, 0.20681829608695168, 0.25330497731750506, 0.12522942698842945, 0.7625671031413557, 0.30016847641118866, 0.3950493166561046, 0.1374334595062722, 0.11615714987559407, 0.05175318558813597, 0.2967716286735184, 0.188552891595703, 0.2502973244069719, 0.1500456109177073, 0.11552184203398703, 0.28599374672475525, 0.12382104743255687, 0.2520251407919299, 0.28051493931623506, 0.05697959704861024, 0.3604558929281744, 0.23543862020484635, 0.17261268112053424, 0.13072872173099284, 0.100902265802077, 0.3677435214483044, 0.15005134373414517, 0.10060503788166651, 0.22261540297219823, 0.15904158116186856, 0.21480377121296132, 0.05370094280324033, 0.6444113136388839, 0.05370094280324033, 0.05370094280324033, 0.2247759349261613, 0.18390758312140468, 0.40459668286709033, 0.12260505541426979, 0.06538936288761056, 0.08633118669312889, 0.09866421336357586, 0.4563219868065384, 0.16032934671581078, 0.19116191339192826, 0.7084531857021833, 0.17711329642554582, 0.780582268176804, 0.173462726261512, 0.44704959837551406, 0.18397810394684616, 0.15818678096364344, 0.12551777185158663, 0.08253223354624875, 0.20783602531690382, 0.06927867510563461, 0.06927867510563461, 0.06927867510563461, 0.6235080759507114, 0.7123025026978568, 0.20401696499994945, 0.2720226199999326, 0.23204739891094953, 0.18394972254093803, 0.10782161225992645, 0.3574103703625356, 0.13985623188099217, 0.1294965110009187, 0.07769790660055122, 0.29525204508209457, 0.25736315156568046, 0.18746204867129812, 0.13662488292992914, 0.12391559149458689, 0.29549102587170717, 0.5213330842736669, 0.050128181180160276, 0.12030763483238466, 0.2205639971927052, 0.08521790800627246, 0.6690641211587549, 0.2545933227032314, 0.32747309065262964, 0.19499386802461233, 0.11952281943701319, 0.10365122552803313, 0.1207784145218716, 0.09259678446676824, 0.2938941420032209, 0.13688220312478783, 0.3542833492641567, 0.15393268478217942, 0.2946367794658903, 0.23485042421566882, 0.21526523887507903, 0.1013619241311226, 0.75690754665126, 0.8026694242590937, 0.6370840372594168, 0.26779125550402144, 0.1964753419210597, 0.1855402351716722, 0.2221490708109259, 0.1280120648814164, 0.7806176200596204, 0.17102266426083634, 0.6840906570433454, 0.17998429435490546, 0.2584132047441939, 0.3257816277708903, 0.12468185754194568, 0.11161037247706428, 0.3541295674080146, 0.17343002274820657, 0.14539043823202946, 0.25443326690605156, 0.07269521911601473, 0.8810651553494667, 0.23672099880436492, 0.2778236802687884, 0.14918751050050008, 0.1430982243576225, 0.19333483503636234, 0.23149145497536053, 0.22902877992243115, 0.14776050317576203, 0.26596890571637166, 0.12436509017293304, 0.6672650618806188, 0.2626138299605056, 0.3882117486372691, 0.19573701611963149, 0.06524567203987716, 0.08808165725383417, 0.2526790347515551, 0.2428888876486351, 0.1748240554092863, 0.20232970679368067, 0.12727191233796042, 0.4898951850062101, 0.17593758966167297, 0.04398439741541824, 0.08645209147168413, 0.20323825012641533, 0.6907602120654308, 0.1535022693478735, 0.07675113467393675, 0.07675113467393675, 0.7690494558809807, 0.7344071075847473, 0.4660081431777383, 0.20711473030121702, 0.10355736515060851, 0.13561083531627305, 0.08629780429217376, 0.17072284090427547, 0.6828913636171019, 0.6343437300802426, 0.3541283959028846, 0.1141405573571281, 0.052680257241751426, 0.17560085747250476, 0.3073015005768833, 0.7187219435809129, 0.18640220694084894, 0.7456088277633958, 0.8594983558402176, 0.7308728828562743, 0.8161449806257106, 0.20930096552065577, 0.12269366944314304, 0.5340783258113285, 0.05773819738500849, 0.07939002140438667, 0.26189843172014615, 0.20128635943949058, 0.143388260544536, 0.16962333660631226, 0.22390280432033222, 0.13630907148834231, 0.6815453574417116, 0.04543635716278077, 0.04543635716278077, 0.09087271432556154, 0.4464799521893468, 0.14615711439382204, 0.1761893981733745, 0.10611406935441874, 0.12613559187412038, 0.19445099264549315, 0.07778039705819725, 0.03889019852909863, 0.5833529779364794, 0.11667059558729588, 0.2029003384211788, 0.3406307005944955, 0.11219985601436046, 0.07659151847686882, 0.26807031466904085, 0.8507316303560551, 0.2106784553080034, 0.1228957655963353, 0.18141755873744736, 0.39209601404545075, 0.08778268971166808, 0.7988150904004444, 0.7933031256705076, 0.6221782702116619, 0.7293044795761962, 0.1857865532060696, 0.7431462128242784, 0.3806418374322343, 0.1807756525778472, 0.15311386091184043, 0.19051572006587777, 0.09467345598365705, 0.3276826363977256, 0.3236957677045899, 0.12188427147586317, 0.1076454547146642, 0.1192263590137727, 0.1631868113490852, 0.25401720634527414, 0.1093043736394816, 0.3263736226981704, 0.1477918291463413, 0.14008451377530423, 0.1375830046007452, 0.3702233578347326, 0.20012073396472033, 0.15009055047354025, 0.28762081481448715, 0.2800518460035796, 0.11504832592579486, 0.22971820341104435, 0.08780003820652765, 0.22209264836647524, 0.14909716253973163, 0.15375644886909826, 0.349446474702496, 0.12424763544977636, 0.24976583102563807, 0.3636771208861681, 0.1397268796306218, 0.18135451813489484, 0.06518436416948177, 0.7826924047220207, 0.20557225989014885, 0.329282163687341, 0.1924376281289655, 0.054371266360247396, 0.21870689165133222, 0.20355755052036517, 0.8142302020814607, 0.6673136070541534, 0.6666350935404438, 0.23849974769653376, 0.27904906494658427, 0.17745776473946845, 0.1194678809302564, 0.18574203385507018, 0.0727493860763048, 0.4905920137966195, 0.24995942908268826, 0.09886455030882446, 0.08953770594006744, 0.640621806004563, 0.08266087819413716, 0.12399131729120574, 0.06199565864560287, 0.08266087819413716, 0.26751457461821765, 0.20755441134172056, 0.3574548195329632, 0.10377720567086028, 0.06226632340251617, 0.27001619414301475, 0.1639384035868304, 0.15108048958002016, 0.33752024267876846, 0.07714748404086136, 0.23577725594509547, 0.1784260315260182, 0.0892130157630091, 0.12744716537572728, 0.3695967795896091, 0.11549141947670366, 0.11549141947670366, 0.692948516860222, 0.5473986870854953, 0.13943174105007902, 0.08779035547597568, 0.16525243383713067, 0.061969662688924, 0.7888831091730072, 0.1972207772932518, 0.23649191662428673, 0.2195996368654091, 0.1810505881848935, 0.1264755305023658, 0.23649191662428673, 0.7113266274617909, 0.34446713233799375, 0.06458758731337383, 0.032293793656686914, 0.15070437039787227, 0.4090547196513676, 0.26299996186359414, 0.24964449505020847, 0.17875778657916164, 0.10170701650193678, 0.20683851167397246, 0.2548343530335755, 0.21828024501646426, 0.28929965487828035, 0.1587492691028831, 0.07833023146523836, 0.18487028360916352, 0.510807630643976, 0.12761568084960914, 0.1003680084519899, 0.07656940850976549, 0.7730872541695046, 0.7799055618295273, 0.12132634137906574, 0.12941476413767014, 0.12941476413767014, 0.48530536551626297, 0.1375031868962745, 0.31963246985604776, 0.20071260636597338, 0.17527016330549788, 0.15378543360998523, 0.1505815704097772, 0.8080915332186484, 0.11322677493947268, 0.11322677493947268, 0.7925874245763088, 0.7750659388410293, 0.11072370554871847, 0.3096922764453321, 0.19136645384121936, 0.1343947614762762, 0.29362333757316866, 0.07011900598762237, 0.09977237979926747, 0.19954475959853493, 0.6984066585948723, 0.749191948478304, 0.8372141542252092, 0.16744283084504183, 0.6788928697283483, 0.6667399288823335, 0.15261451479248964, 0.07630725739624482, 0.6867653165662033, 0.07630725739624482, 0.07630725739624482, 0.686371261145671, 0.1344607919088662, 0.1344607919088662, 0.1344607919088662, 0.672303959544331, 0.4585203464353797, 0.16294949531391859, 0.07093700426915067, 0.14341611732676116, 0.1634635315767385, 0.5256327038586964, 0.12032555871464135, 0.12032555871464135, 0.117792389057491, 0.11652580422891583, 0.2529198774917797, 0.5113380131899025, 0.11546342233320378, 0.09896864771417467, 0.027491291031715184, 0.7892965250261156, 0.42587196261098653, 0.1990951425206362, 0.09475651168094451, 0.1873836635488341, 0.09156247196136211, 0.8058407945543904, 0.1007300993192988, 0.8451758536943522, 0.10147087894671765, 0.050735439473358825, 0.12683859868339706, 0.5327221144702676, 0.2029417578934353, 0.2621682327218258, 0.1622111138914307, 0.20605195548370925, 0.17536336636911426, 0.19377651983787125, 0.2925166914692229, 0.2124186348184224, 0.2755796574637673, 0.1411419500454634, 0.07868663715034585, 0.1194741721077155, 0.1194741721077155, 0.1194741721077155, 0.7168450326462931, 0.2842587853055744, 0.10591295624635784, 0.3772947863852018, 0.191222784225947, 0.0412062565335374, 0.22992357356199813, 0.34256290000398715, 0.1300577789845646, 0.13702516000159484, 0.16024976339169567, 0.4647186269887203, 0.1273059935848833, 0.15007617129925266, 0.19147649441628786, 0.06675802102621928, 0.20993143465793132, 0.21067719463895418, 0.18942303517980305, 0.2572871934528821, 0.1327452766220667, 0.22879698858550784, 0.14901909124977156, 0.3431954828782618, 0.13697714448211326, 0.14149287451998513, 0.7346610694650338, 0.7189610513481484, 0.08987013141851855, 0.08987013141851855, 0.24352541909643197, 0.36237514516263325, 0.16662265517124294, 0.14642596969594077, 0.08117513969881066, 0.7129003880171082, 0.10184291257387261, 0.10184291257387261, 0.25937904051002975, 0.3770708518427745, 0.17653771699911716, 0.09312507401571553, 0.09312507401571553, 0.6728708651761518, 0.7395385186365817, 0.7127773526409978, 0.6489308391808544, 0.2420186909955305, 0.08916478089309018, 0.1910673876280504, 0.3515639932356127, 0.12737825841870026, 0.7750389427985371, 0.17737088522110175, 0.538805896615045, 0.16398440331762237, 0.06693240951739689, 0.05689254808978735, 0.7559884402432987, 0.6797813841406938, 0.7293790870242645, 0.2843260601261138, 0.17830617329942727, 0.21746124513882853, 0.15240358731336182, 0.16686084460790998, 0.7054871201979401, 0.20101141701592412, 0.09910979588979592, 0.2247419315247485, 0.33222720312354126, 0.1437789996711124, 0.17397263648006622, 0.6958905459202649, 0.3097882402773125, 0.41305098703641663, 0.1016740891166564, 0.10485140440155191, 0.07148959391014903, 0.3730080313082615, 0.19291308835702184, 0.19419490289760008, 0.146767764896206, 0.09293155419192083, 0.2434557729526595, 0.2502355539715943, 0.17935602513727575, 0.255782647532541, 0.07149587256331266, 0.12122919834709557, 0.848604388429669, 0.7655140668237879, 0.25921090340836456, 0.6480272585209114, 0.2674959206844287, 0.2006219405133215, 0.26896567849038705, 0.11023183544687995, 0.15211993291669432, 0.18209264072778705, 0.7283705629111482, 0.14779854217280186, 0.3052361197046995, 0.10281637716368826, 0.12530745966824505, 0.31808816685016056, 0.23909939705934294, 0.1638583280546546, 0.16887439932163384, 0.15382618552069616, 0.2725398721725378, 0.1944803837149816, 0.15006202447143643, 0.3193319880752167, 0.19928236849806757, 0.13805706251372152, 0.15718293184955384, 0.5079819254475647, 0.11970885538211054, 0.16030577155517411, 0.055170168132624854, 0.7641940904783233, 0.6712040667559945, 0.15404096281757887, 0.7702048140878944, 0.3770834528658199, 0.27969103788723065, 0.09453842479606649, 0.1569694600387519, 0.09168443461354372, 0.31311441534646206, 0.2469967409143283, 0.1846572193068879, 0.16482191697724774, 0.09020339868955393, 0.8098305120056538, 0.622907195102941, 0.8574196464320565, 0.13651653079898124, 0.5838960052245582, 0.0888179838933131, 0.12500308844244065, 0.06579109918023192, 0.8763192533998166, 0.19920409946801432, 0.23542302664401693, 0.31938508509747754, 0.14158307896073746, 0.10371783691309837, 0.22217937584586872, 0.4317143969688018, 0.1499259202862366, 0.09392949222752173, 0.10296117417247574, 0.6344320430009359, 0.10970774044682999, 0.7679541831278099, 0.07135411042499776, 0.07135411042499776, 0.21406233127499327, 0.07135411042499776, 0.6421869938249799, 0.637286899546675, 0.8864454207958006, 0.2789527508137521, 0.21639970972218342, 0.11834359125431906, 0.12003421398652361, 0.2654277689561156, 0.7654296683323399, 0.2524816815118028, 0.1157207706929096, 0.15780105094487673, 0.0631204203779507, 0.39976266239368774, 0.1636039047353983, 0.44650232334035783, 0.1636039047353983, 0.06475987895776182, 0.16019549005341083, 0.3377497286491397, 0.22416638081662446, 0.20916480657459416, 0.10415378688038192, 0.12472737441230922, 0.7748112846778504, 0.05605401346872195, 0.05605401346872195, 0.7287021750933853, 0.05605401346872195, 0.05605401346872195, 0.04038763300313706, 0.3150235374244691, 0.11308537240878377, 0.1292404256100386, 0.411953856631998, 0.6481623912783812, 0.5218127352430342, 0.22425010109618, 0.16387507387797767, 0.03450001555325846, 0.056062525274045, 0.11922917524131038, 0.15391402622060066, 0.1799276644550684, 0.3771977543997819, 0.1712564517102458, 0.159033850954068, 0.79516925477034, 0.23682617689987, 0.33648075628842916, 0.21806766783849416, 0.12134410549077497, 0.08734430781703126, 0.20412263384601642, 0.8164905353840657, 0.7046990665472721, 0.37511748410097284, 0.16940789604560066, 0.27894984386456045, 0.08948048644513869, 0.08693299928655823, 0.1721853852476184, 0.18993645589170277, 0.2591656314036318, 0.31774416452911025, 0.0621287472542953, 0.8148929625757867, 0.889833279915674, 0.6221218227843179, 0.7994148234817656, 0.1332358039136276, 0.11036708498161335, 0.33110125494484005, 0.144326188052879, 0.09055760819004173, 0.32544140443296243, 0.7812867518592083, 0.7060434084944716, 0.07844926761049685, 0.07844926761049685, 0.07844926761049685, 0.07844926761049685, 0.05793067861318416, 0.05793067861318416, 0.23172271445273665, 0.11586135722636833, 0.5793067861318416, 0.3799874626057636, 0.16975592526584987, 0.21687678708341676, 0.15223663048752373, 0.08155533776117344, 0.7827408587165888, 0.1956852146791472, 0.6836396717442029, 0.04021409833789429, 0.12064229501368288, 0.08042819667578859, 0.04021409833789429, 0.7686083521236888, 0.6484891445997616, 0.2637110265950974, 0.19778326994632303, 0.2767721859311753, 0.15673391203293524, 0.10511123465700815, 0.676289582357559, 0.16907239558938975, 0.8102682390182113, 0.20426942079247185, 0.2009189108833553, 0.3146128804660433, 0.18762855491052635, 0.092697440818891, 0.20236329953228235, 0.8094531981291294, 0.10529505902129414, 0.10529505902129414, 0.10529505902129414, 0.10529505902129414, 0.6317703541277648, 0.6345914543233211, 0.7774313580265252, 0.322199546042077, 0.0943816852042448, 0.0911271443351329, 0.1855088295393777, 0.3091813825656295, 0.7724674465731513, 0.15355062573553732, 0.6142025029421493, 0.2961053958706529, 0.23550213711077062, 0.1286490229815045, 0.22965445424797495, 0.11057436686013608, 0.6484083308378691, 0.17637991040260065, 0.4291254244711317, 0.10198503199256517, 0.1276044603191999, 0.16554092149517827, 0.7385282810004833, 0.29462937119049126, 0.3655024158067606, 0.130608896507125, 0.11997793981468459, 0.08960377783628343, 0.13252995683496868, 0.05301198273398747, 0.6626497841748434, 0.10602396546797493, 0.05301198273398747, 0.4313339738645119, 0.19471647963026537, 0.14377799128817065, 0.12816780937688355, 0.10187697668418948, 0.23267148241118168, 0.19711371433505426, 0.17179812945476788, 0.13624036137864043, 0.26204529082189565, 0.6352462811713918, 0.8657419443237684, 0.8654315823800893, 0.7186233513558296, 0.2363730155104673, 0.15872154967128485, 0.27283827410161376, 0.1813495449577552, 0.15074477435447156, 0.4491293818105087, 0.26943002660810594, 0.11972023267126969, 0.0821142748938132, 0.0797341509838476, 0.16717929976923163, 0.6687171990769265, 0.7403415943869648, 0.107278768693274, 0.750951380852918, 0.03575958956442467, 0.07151917912884934, 0.03575958956442467, 0.8762686111539664, 0.7904125185489741, 0.1571225245224847, 0.21789633117740803, 0.2342014988165338, 0.28756386563549086, 0.10376015770352763, 0.8204384173083018, 0.5215839736749432, 0.14181315413281867, 0.08172283458501416, 0.10816257518604815, 0.14662037969664304], \"Term\": [\"1\", \"1\", \"1\", \"1\", \"1\", \"100lbs\", \"100lbs\", \"100lbs\", \"100lbs\", \"11000\", \"1200lm\", \"1200lm\", \"2\", \"2\", \"2\", \"2\", \"2\", \"20000\", \"20s\", \"20s\", \"20s\", \"20s\", \"2xl\", \"2xl\", \"2xl\", \"2xl\", \"2xl\", \"336\", \"44cm\", \"500lbs\", \"505\", \"640\", \"642\", \"82a\", \"8lb\", \"929\", \"930\", \"aac\", \"advertise\", \"advertise\", \"advertise\", \"advertise\", \"advertise\", \"air\", \"air\", \"air\", \"air\", \"air\", \"ak47\", \"also\", \"also\", \"also\", \"also\", \"also\", \"amd\", \"america\", \"america\", \"america\", \"america\", \"aok\", \"apparantly\", \"ar556\", \"around\", \"around\", \"around\", \"around\", \"around\", \"arrows\", \"arrows\", \"arrows\", \"arrows\", \"arrows\", \"authenticity\", \"automate\", \"awesome\", \"awesome\", \"awesome\", \"awesome\", \"awesome\", \"back\", \"back\", \"back\", \"back\", \"back\", \"bag\", \"bag\", \"bag\", \"bag\", \"bag\", \"ball\", \"ball\", \"ball\", \"ball\", \"ball\", \"band\", \"band\", \"band\", \"band\", \"band\", \"barbell\", \"barbell\", \"barbell\", \"bat\", \"bat\", \"bat\", \"bat\", \"bat\", \"batman\", \"battery\", \"battery\", \"battery\", \"battery\", \"battery\", \"bdc\", \"bdc\", \"bdc\", \"bdc\", \"bear\", \"bear\", \"bear\", \"bear\", \"bear\", \"belt\", \"belt\", \"belt\", \"belt\", \"belt\", \"best\", \"best\", \"best\", \"best\", \"best\", \"better\", \"better\", \"better\", \"better\", \"better\", \"bike\", \"bike\", \"bike\", \"bike\", \"bike\", \"bite\", \"bite\", \"bite\", \"bite\", \"bite\", \"blocker\", \"boresnakes\", \"bottle\", \"bottle\", \"bottle\", \"bottle\", \"bottle\", \"boulders\", \"bow\", \"bow\", \"bow\", \"bow\", \"bow\", \"bracelets\", \"bracelets\", \"bracelets\", \"bracelets\", \"bracelets\", \"brutally\", \"builder\", \"bungie\", \"bungie\", \"bungie\", \"buts\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"camp\", \"camp\", \"camp\", \"camp\", \"camp\", \"canteens\", \"capris\", \"capris\", \"capris\", \"capris\", \"capris\", \"case\", \"case\", \"case\", \"case\", \"case\", \"castelli\", \"centre\", \"cf\", \"chromium\", \"civic\", \"class\", \"class\", \"class\", \"class\", \"class\", \"clean\", \"clean\", \"clean\", \"clean\", \"clean\", \"clip\", \"clip\", \"clip\", \"clip\", \"clip\", \"coffee\", \"coffee\", \"coffee\", \"coffee\", \"coffee\", \"color\", \"color\", \"color\", \"color\", \"color\", \"come\", \"come\", \"come\", \"come\", \"come\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfortable\", \"contraption\", \"countersink\", \"countersink\", \"countless\", \"countless\", \"cowboys\", \"cowboys\", \"cowboys\", \"crossbow\", \"crossbow\", \"crossbow\", \"crossbow\", \"crossbow\", \"crow\", \"crud\", \"customizable\", \"cutter\", \"cutter\", \"cutter\", \"cutter\", \"cutter\", \"dallas\", \"day\", \"day\", \"day\", \"day\", \"day\", \"dc\", \"de\", \"de\", \"de\", \"de\", \"de\", \"delivery\", \"delivery\", \"delivery\", \"delivery\", \"delivery\", \"dental\", \"deny\", \"deterioration\", \"devise\", \"devise\", \"dh\", \"diablo\", \"dillon\", \"dillon\", \"drawstrings\", \"drawstrings\", \"easy\", \"easy\", \"easy\", \"easy\", \"easy\", \"efficent\", \"electricity\", \"electricity\", \"emblem\", \"emblem\", \"emblem\", \"emblem\", \"en\", \"en\", \"enamel\", \"enamel\", \"end\", \"end\", \"end\", \"end\", \"end\", \"endanger\", \"enough\", \"enough\", \"enough\", \"enough\", \"enough\", \"even\", \"even\", \"even\", \"even\", \"even\", \"excelent\", \"excelent\", \"excelent\", \"excelent\", \"excelente\", \"excelente\", \"excelente\", \"excelente\", \"excellant\", \"excellant\", \"exelent\", \"exercise\", \"exercise\", \"exercise\", \"exercise\", \"exercise\", \"expect\", \"expect\", \"expect\", \"expect\", \"expect\", \"extra\", \"extra\", \"extra\", \"extra\", \"extra\", \"far\", \"far\", \"far\", \"far\", \"far\", \"fde\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"find\", \"find\", \"find\", \"find\", \"find\", \"fine\", \"fine\", \"fine\", \"fine\", \"fine\", \"first\", \"first\", \"first\", \"first\", \"first\", \"fit\", \"fit\", \"fit\", \"fit\", \"fit\", \"flake\", \"flake\", \"flake\", \"flake\", \"flake\", \"foam\", \"foam\", \"foam\", \"foam\", \"foam\", \"fog\", \"fog\", \"fog\", \"fog\", \"fog\", \"fond\", \"fond\", \"frogg\", \"frogg\", \"front\", \"front\", \"front\", \"front\", \"front\", \"garment\", \"garment\", \"garment\", \"garment\", \"garment\", \"georgiadogscom\", \"get\", \"get\", \"get\", \"get\", \"get\", \"gift\", \"gift\", \"gift\", \"gift\", \"gift\", \"glass\", \"glass\", \"glass\", \"glass\", \"glass\", \"glock\", \"glock\", \"glock\", \"glock\", \"glock\", \"gnomes\", \"go\", \"go\", \"go\", \"go\", \"go\", \"goggle\", \"goggle\", \"goggle\", \"goggle\", \"goggle\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gostik\", \"graduate\", \"grat\", \"great\", \"great\", \"great\", \"great\", \"great\", \"greati\", \"grin\", \"grin\", \"grip\", \"grip\", \"grip\", \"grip\", \"grip\", \"gun\", \"gun\", \"gun\", \"gun\", \"gun\", \"gymnastics\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"happy\", \"happy\", \"happy\", \"happy\", \"happy\", \"hearty\", \"highly\", \"highly\", \"highly\", \"highly\", \"highly\", \"hold\", \"hold\", \"hold\", \"hold\", \"hold\", \"holster\", \"holster\", \"holster\", \"holster\", \"holster\", \"hoppes\", \"hoppes\", \"hoppes\", \"hoppes\", \"hs\", \"hum\", \"husband\", \"husband\", \"husband\", \"husband\", \"husband\", \"hydraulic\", \"hydraulic\", \"ilbe\", \"image\", \"image\", \"image\", \"image\", \"image\", \"imr\", \"inhumane\", \"inhumane\", \"israeli\", \"joggers\", \"jsb\", \"junk\", \"junk\", \"junk\", \"junk\", \"junk\", \"keep\", \"keep\", \"keep\", \"keep\", \"keep\", \"kershaw\", \"kershaw\", \"kershaw\", \"kershaw\", \"kershaw\", \"kit\", \"kit\", \"kit\", \"kit\", \"kit\", \"kite\", \"kite\", \"kite\", \"kite\", \"kite\", \"knife\", \"knife\", \"knife\", \"knife\", \"knife\", \"kokanee\", \"laser\", \"laser\", \"laser\", \"laser\", \"laser\", \"leafy\", \"leki\", \"lenght\", \"leonard\", \"leotard\", \"leotard\", \"light\", \"light\", \"light\", \"light\", \"light\", \"like\", \"like\", \"like\", \"like\", \"like\", \"line\", \"line\", \"line\", \"line\", \"line\", \"link\", \"link\", \"link\", \"link\", \"link\", \"little\", \"little\", \"little\", \"little\", \"little\", \"lock\", \"lock\", \"lock\", \"lock\", \"lock\", \"look\", \"look\", \"look\", \"look\", \"look\", \"louisville\", \"love\", \"love\", \"love\", \"love\", \"love\", \"m2\", \"m2\", \"m48\", \"madevery\", \"make\", \"make\", \"make\", \"make\", \"make\", \"mat\", \"mat\", \"mat\", \"mat\", \"mat\", \"maxpedition\", \"maxpedition\", \"maxpedition\", \"maxpedition\", \"maxpedition\", \"maybe\", \"maybe\", \"maybe\", \"maybe\", \"maybe\", \"miles\", \"miles\", \"miles\", \"miles\", \"miles\", \"mini\", \"mini\", \"mini\", \"mini\", \"mini\", \"monkey\", \"monkey\", \"monkey\", \"mountain\", \"mountain\", \"mountain\", \"mountain\", \"mountain\", \"mp5\", \"mp5\", \"much\", \"much\", \"much\", \"much\", \"much\", \"mystic\", \"nassl\", \"nassl\", \"nassl\", \"nassl\", \"nassl\", \"need\", \"need\", \"need\", \"need\", \"need\", \"new\", \"new\", \"new\", \"new\", \"new\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"nissan\", \"nonstop\", \"nose\", \"nose\", \"nose\", \"nose\", \"nose\", \"one\", \"one\", \"one\", \"one\", \"one\", \"operations\", \"pa\", \"pa\", \"pa\", \"packers\", \"packers\", \"pad\", \"pad\", \"pad\", \"pad\", \"pad\", \"pancake\", \"pancake\", \"pancake\", \"pantry\", \"participate\", \"participate\", \"partition\", \"pastel\", \"pc\", \"pc\", \"pc\", \"pc\", \"pc\", \"pd35\", \"pedestrians\", \"pedestrians\", \"pedestrians\", \"pedestrians\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"perfectly\", \"perfectly\", \"perfectly\", \"perfectly\", \"perfectly\", \"pillow\", \"pillow\", \"pillow\", \"pillow\", \"pillow\", \"pity\", \"pocket\", \"pocket\", \"pocket\", \"pocket\", \"pocket\", \"prefect\", \"prefect\", \"presence\", \"presta\", \"presta\", \"presta\", \"presta\", \"presta\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"price\", \"price\", \"price\", \"price\", \"price\", \"primos\", \"primos\", \"primos\", \"primos\", \"product\", \"product\", \"product\", \"product\", \"product\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"put\", \"put\", \"put\", \"put\", \"put\", \"quality\", \"quality\", \"quality\", \"quality\", \"quality\", \"range\", \"range\", \"range\", \"range\", \"range\", \"razer\", \"rd\", \"rd\", \"rd\", \"really\", \"really\", \"really\", \"really\", \"really\", \"reccomend\", \"reccomend\", \"reccomend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"reconnect\", \"redskins\", \"richt\", \"riden\", \"ring\", \"ring\", \"ring\", \"ring\", \"ring\", \"rocker\", \"rod\", \"rod\", \"rod\", \"rod\", \"rod\", \"roger\", \"s2\", \"sanitary\", \"say\", \"say\", \"say\", \"say\", \"say\", \"scalpel\", \"scope\", \"scope\", \"scope\", \"scope\", \"scope\", \"scosche\", \"scosche\", \"seat\", \"seat\", \"seat\", \"seat\", \"seat\", \"see\", \"see\", \"see\", \"see\", \"see\", \"seem\", \"seem\", \"seem\", \"seem\", \"seem\", \"sensei\", \"sensei\", \"serengeti\", \"serfas\", \"serfas\", \"set\", \"set\", \"set\", \"set\", \"set\", \"shank\", \"shank\", \"sheath\", \"sheath\", \"sheath\", \"sheath\", \"sheath\", \"ship\", \"ship\", \"ship\", \"ship\", \"ship\", \"shoot\", \"shoot\", \"shoot\", \"shoot\", \"shoot\", \"short\", \"short\", \"short\", \"short\", \"short\", \"shorty\", \"shrader\", \"sidewall\", \"sidewall\", \"size\", \"size\", \"size\", \"size\", \"size\", \"small\", \"small\", \"small\", \"small\", \"small\", \"smartwool\", \"snd\", \"snub\", \"sock\", \"sock\", \"sock\", \"sock\", \"sock\", \"sofft\", \"solid\", \"solid\", \"solid\", \"solid\", \"solid\", \"son\", \"son\", \"son\", \"son\", \"son\", \"soothe\", \"stationary\", \"stationary\", \"stepper\", \"stepper\", \"stepper\", \"stepper\", \"stepper\", \"stil\", \"strengths\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"stumpjumper\", \"survival\", \"survival\", \"survival\", \"survival\", \"survival\", \"sweat\", \"sweat\", \"sweat\", \"sweat\", \"sweat\", \"take\", \"take\", \"take\", \"take\", \"take\", \"talley\", \"talon\", \"talon\", \"talon\", \"talon\", \"talon\", \"tee\", \"tee\", \"tee\", \"tee\", \"tee\", \"tenkara\", \"tent\", \"tent\", \"tent\", \"tent\", \"tent\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank\", \"thieve\", \"thieve\", \"think\", \"think\", \"think\", \"think\", \"think\", \"thompson\", \"thompson\", \"thomson\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tire\", \"tire\", \"tire\", \"tire\", \"tire\", \"tomato\", \"tomatoes\", \"tombstone\", \"tourna\", \"tourna\", \"towel\", \"towel\", \"towel\", \"towel\", \"towel\", \"trials\", \"triathlon\", \"triathlon\", \"triathlon\", \"triathlon\", \"triathlon\", \"trike\", \"trike\", \"trike\", \"trike\", \"trike\", \"try\", \"try\", \"try\", \"try\", \"try\", \"ts\", \"ts\", \"tumbler\", \"tumbler\", \"tumbler\", \"tumbler\", \"tumbler\", \"turf\", \"tusa\", \"two\", \"two\", \"two\", \"two\", \"two\", \"unreal\", \"unreal\", \"unsurpassed\", \"use\", \"use\", \"use\", \"use\", \"use\", \"vanity\", \"vanity\", \"vanquisher\", \"vanquisher\", \"vanquisher\", \"vanquisher\", \"vanquisher\", \"variations\", \"vendedor\", \"video\", \"video\", \"video\", \"video\", \"video\", \"vis\", \"wagon\", \"wagon\", \"want\", \"want\", \"want\", \"want\", \"want\", \"wast\", \"water\", \"water\", \"water\", \"water\", \"water\", \"watery\", \"wear\", \"wear\", \"wear\", \"wear\", \"wear\", \"weaver\", \"weaver\", \"weaver\", \"weaver\", \"weaver\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"well\", \"well\", \"well\", \"well\", \"well\", \"wich\", \"wight\", \"withings\", \"wive\", \"work\", \"work\", \"work\", \"work\", \"work\", \"would\", \"would\", \"would\", \"would\", \"would\", \"xtr\", \"xtr\", \"xx1\", \"xxl\", \"xxl\", \"xxl\", \"xxl\", \"xxl\", \"xxx\", \"yankee\", \"yet\", \"yet\", \"yet\", \"yet\", \"yet\", \"zensah\", \"zipper\", \"zipper\", \"zipper\", \"zipper\", \"zipper\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 5, 2, 4, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el2053623725620009606193091917\", ldavis_el2053623725620009606193091917_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el2053623725620009606193091917\", ldavis_el2053623725620009606193091917_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el2053623725620009606193091917\", ldavis_el2053623725620009606193091917_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "2     -0.002606  0.005175       1        1  27.702886\n",
       "4     -0.008082  0.023669       2        1  23.387320\n",
       "1      0.017859 -0.010135       3        1  19.072693\n",
       "3      0.016620 -0.001468       4        1  16.239383\n",
       "0     -0.023790 -0.017241       5        1  13.597718, topic_info=        Term         Freq        Total Category  logprob  loglift\n",
       "155     well  5174.000000  5174.000000  Default  30.0000  30.0000\n",
       "28       use  8953.000000  8953.000000  Default  29.0000  29.0000\n",
       "160      bag  2455.000000  2455.000000  Default  28.0000  28.0000\n",
       "353  product  3106.000000  3106.000000  Default  27.0000  27.0000\n",
       "49      work  6142.000000  6142.000000  Default  26.0000  26.0000\n",
       "..       ...          ...          ...      ...      ...      ...\n",
       "61        go   320.243944  3087.276570   Topic5  -5.6580  -0.2707\n",
       "50     would   334.565046  4201.461932   Topic5  -5.6143  -0.5351\n",
       "162     easy   288.992875  2590.997040   Topic5  -5.7607  -0.1981\n",
       "9       hold   272.896988  2145.013735   Topic5  -5.8180  -0.0665\n",
       "454     time   272.945109  3140.349490   Topic5  -5.8178  -0.4476\n",
       "\n",
       "[484 rows x 6 columns], token_table=      Topic      Freq    Term\n",
       "term                         \n",
       "271       1  0.180576       1\n",
       "271       2  0.235668       1\n",
       "271       3  0.184657       1\n",
       "271       4  0.251991       1\n",
       "271       5  0.145889       1\n",
       "...     ...       ...     ...\n",
       "537       1  0.521584  zipper\n",
       "537       2  0.141813  zipper\n",
       "537       3  0.081723  zipper\n",
       "537       4  0.108163  zipper\n",
       "537       5  0.146620  zipper\n",
       "\n",
       "[1104 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 5, 2, 4, 1])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Case: kompletter Datensatz\n",
    "Wie bereits in Task 1 ist hier das Problem, dass der Datensatz so groß ist, dass die Bearbeitung sehr lange dauert. In den weiteren Schritten werden Use Cases betrachtet in denen nur ein Teil des Datensatzes betrachtet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all = df[['reviewerID', 'asin', 'unixReviewTime', 'overall', 'reviewText']]\n",
    "\n",
    "# clean_text(df_all)\n",
    "\n",
    "# df_all['adjectives'] = df_all['reviewText_tokenize'].apply(get_adjectives)\n",
    "# # df_all['nouns'] = df_all['reviewText_tokenize'].apply(get_nouns)\n",
    "# # df_all['verbs'] = df_all['reviewText_tokenize'].apply(get_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = df_all.reviewText_tokenize.values.tolist()\n",
    "# id2word = corpora.Dictionary(data)\n",
    "# corpus = [id2word.doc2bow(elem) for elem in data]\n",
    "# lda_model = gensim.models.LdaMulticore(corpus=corpus, id2word=id2word, num_topics=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Case: Reviews von Artikel 'B0010O748Q'\n",
    "Wie bereits in Task 1 für die Assoziationsanalyse, wird auch hier der Datensatz auf den Artikel 'B0010O748Q' reduziert, das am häufigsten gekaufte Artikel.\n",
    "Das Ziel ist es, häufig genannte Themen in den Reviews zu dem Artikel zu finden. Damit könnten die Reviews nach diesen gefiltert werden, um Meinungen zu spezifischen Aspekten des Artikels zu finden. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Zuerst wird der Datensatz wieder für das Topic Modeling aufbereitet mit den oben erstellten Funktionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3845, 5)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fire = df.loc[(df['asin'] == 'B0010O748Q') & (df['verified'] == True)]\n",
    "df_fire = df_fire[['reviewerID', 'asin', 'unixReviewTime', 'overall', 'reviewText']]\n",
    "df_fire.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text(df_fire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fire['adjectives'] = df_fire['reviewText_tokenize'].apply(get_adjectives)\n",
    "df_fire['nouns'] = df_fire['reviewText_tokenize'].apply(get_nouns)\n",
    "df_fire['verbs'] = df_fire['reviewText_tokenize'].apply(get_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewText_tokenize</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>356240</th>\n",
       "      <td>A31Y28UEDXQ0HB</td>\n",
       "      <td>B0010O748Q</td>\n",
       "      <td>1240617600</td>\n",
       "      <td>5</td>\n",
       "      <td>this fire starter works great just follow the ...</td>\n",
       "      <td>[fire, starter, work, great, follow, instructi...</td>\n",
       "      <td>[great, follow, first]</td>\n",
       "      <td>[fire, starter, work, instructions, day, fire,...</td>\n",
       "      <td>[try, start]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356246</th>\n",
       "      <td>A37CBUJOWJRTG0</td>\n",
       "      <td>B0010O748Q</td>\n",
       "      <td>1524268800</td>\n",
       "      <td>2</td>\n",
       "      <td>i bought this fire starter for my nephew to us...</td>\n",
       "      <td>[buy, fire, starter, nephew, use, boy, scout, ...</td>\n",
       "      <td>[first, even, scrap, pile, first, magnesium, w...</td>\n",
       "      <td>[fire, starter, nephew, use, boy, scout, try, ...</td>\n",
       "      <td>[buy, try, stave, get, need, get, come, get, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356247</th>\n",
       "      <td>A682D3WQLGZH0</td>\n",
       "      <td>B0010O748Q</td>\n",
       "      <td>1523923200</td>\n",
       "      <td>4</td>\n",
       "      <td>delivered as promised and is in my bug out bag</td>\n",
       "      <td>[deliver, promise, bug, bag]</td>\n",
       "      <td>[deliver]</td>\n",
       "      <td>[promise, bug, bag]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356248</th>\n",
       "      <td>A2TEAYT22A2TBW</td>\n",
       "      <td>B0010O748Q</td>\n",
       "      <td>1522627200</td>\n",
       "      <td>3</td>\n",
       "      <td>is ok you get what you pay for works so thats ...</td>\n",
       "      <td>[ok, get, pay, work, thats, main, thing, would...</td>\n",
       "      <td>[ok, pay, main, would, ergonomic, handle, fit,...</td>\n",
       "      <td>[work, thats, thing, hand, pocket, everything,...</td>\n",
       "      <td>[get, prefer, want]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356249</th>\n",
       "      <td>A3B14M2M9PWS8B</td>\n",
       "      <td>B0010O748Q</td>\n",
       "      <td>1522108800</td>\n",
       "      <td>5</td>\n",
       "      <td>great product good quality long-lasting fast s...</td>\n",
       "      <td>[great, product, good, quality, long, last, fa...</td>\n",
       "      <td>[great, good, long, last, fast, would]</td>\n",
       "      <td>[product, quality, ship]</td>\n",
       "      <td>[recommend]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID        asin  unixReviewTime  overall  \\\n",
       "356240  A31Y28UEDXQ0HB  B0010O748Q      1240617600        5   \n",
       "356246  A37CBUJOWJRTG0  B0010O748Q      1524268800        2   \n",
       "356247   A682D3WQLGZH0  B0010O748Q      1523923200        4   \n",
       "356248  A2TEAYT22A2TBW  B0010O748Q      1522627200        3   \n",
       "356249  A3B14M2M9PWS8B  B0010O748Q      1522108800        5   \n",
       "\n",
       "                                               reviewText  \\\n",
       "356240  this fire starter works great just follow the ...   \n",
       "356246  i bought this fire starter for my nephew to us...   \n",
       "356247     delivered as promised and is in my bug out bag   \n",
       "356248  is ok you get what you pay for works so thats ...   \n",
       "356249  great product good quality long-lasting fast s...   \n",
       "\n",
       "                                      reviewText_tokenize  \\\n",
       "356240  [fire, starter, work, great, follow, instructi...   \n",
       "356246  [buy, fire, starter, nephew, use, boy, scout, ...   \n",
       "356247                       [deliver, promise, bug, bag]   \n",
       "356248  [ok, get, pay, work, thats, main, thing, would...   \n",
       "356249  [great, product, good, quality, long, last, fa...   \n",
       "\n",
       "                                               adjectives  \\\n",
       "356240                             [great, follow, first]   \n",
       "356246  [first, even, scrap, pile, first, magnesium, w...   \n",
       "356247                                          [deliver]   \n",
       "356248  [ok, pay, main, would, ergonomic, handle, fit,...   \n",
       "356249             [great, good, long, last, fast, would]   \n",
       "\n",
       "                                                    nouns  \\\n",
       "356240  [fire, starter, work, instructions, day, fire,...   \n",
       "356246  [fire, starter, nephew, use, boy, scout, try, ...   \n",
       "356247                                [promise, bug, bag]   \n",
       "356248  [work, thats, thing, hand, pocket, everything,...   \n",
       "356249                           [product, quality, ship]   \n",
       "\n",
       "                                                    verbs  \n",
       "356240                                       [try, start]  \n",
       "356246  [buy, try, stave, get, need, get, come, get, g...  \n",
       "356247                                                 []  \n",
       "356248                                [get, prefer, want]  \n",
       "356249                                        [recommend]  "
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fire.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDAMulticore - kompletter Reviewtext\n",
    "Zuerst wird der komplette Reviewtext für das Lda Topic Modeling genutzt. Die Anzahl an Durchläufen durch den Corpus wurde auf 20 gesetzt um einigermaßen konsistente Ergebnisse zu erhalten. Bei nur einen Durchlauf können sich die Gewichtungen der Themen in den einzelnen Dokumenten stark ändern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fire = df_fire.reviewText_tokenize.values.tolist()\n",
    "id2word_fire = corpora.Dictionary(data_fire)\n",
    "corpus_fire = [id2word_fire.doc2bow(elem) for elem in data_fire]\n",
    "lda_model_fire = gensim.models.LdaMulticore(corpus=corpus_fire, id2word=id2word_fire, num_topics=5, passes = 20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur Prüfung werden wieder die ersten drei Reviews angezeigt mit ihren jeweiligen Gewichtungen von Themen.\n",
    "Interessant ist hier, dass der zweite Text fast komplett den Thema 4 zugeordnet wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . Reviewtext:  this fire starter works great just follow the instructions i tried it the other day and i started a fire the first time\n",
      "Thema  0 :  1.5656348317861557 %\n",
      "Thema  1 :  1.567627303302288 %\n",
      "Thema  2 :  1.5905288979411125 %\n",
      "Thema  3 :  93.71214509010315 %\n",
      "Thema  4 :  1.5640633180737495 %\n",
      "\n",
      "2 . Reviewtext:  i bought this fire starter for my nephew to use for boy scouts  he tried it out first by trying to start a fire for the wood stove even scraping the magnesium part in a pile first before using the flint  getting the magnesium part was a learning experience as well  it is hard to scrape off (you need an actual knife of some sort to get it to come off)  but this part does help get a fire started much easier than without\n",
      "\n",
      "when he went to get a spark from the flint (after scraping the magnesium in a little pile) it did spark (the first time) but not enough to get a fire started  the thing that came with it to spark the flint was so small that even his hands had a hard time grasping on to it  and when he went to use it the 2nd time the flint part broke in half then again into more than 2 pieces  he was able to get a couple sparks anyway from one of the pieces which did start a small fire but that did not stay lit (it went out fast)\n",
      "\n",
      "overall i wouldn't recommend this for starting fires if for example in the woods while camping but i will say that the magnesium part on it is a good thing to have on hand  that part works\n",
      "Thema  3 :  99.24731850624084 %\n",
      "\n",
      "3 . Reviewtext:  delivered as promised and is in my bug out bag\n",
      "Thema  0 :  50.51698684692383 %\n",
      "Thema  1 :  4.001354053616524 %\n",
      "Thema  2 :  37.408554553985596 %\n",
      "Thema  3 :  4.066302999854088 %\n",
      "Thema  4 :  4.006797820329666 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_text_topic(df_fire, lda_model_fire, id2word_fire, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In jedem Thema ist das Wort 'fire' vertreten und auch andere Wörter sind vorne bei vielen mit dabei. Deswegen ist die Normalisierung der Werte besonders wichtig, damit die wichtigsten aber auch einzigartigeren Wörter für jedes Thema auftauchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.020*\"work\" + 0.019*\"use\" + 0.014*\"expect\" + 0.012*\"magnesium\" + 0.012*\"advertise\" + 0.011*\"fire\" + 0.010*\"say\" + 0.010*\"item\" + 0.010*\"come\" + 0.010*\"time\"'),\n",
       " (1,\n",
       "  '0.039*\"fire\" + 0.031*\"magnesium\" + 0.018*\"spark\" + 0.017*\"use\" + 0.015*\"make\" + 0.013*\"get\" + 0.013*\"shave\" + 0.012*\"start\" + 0.011*\"one\" + 0.011*\"starter\"'),\n",
       " (2,\n",
       "  '0.051*\"work\" + 0.039*\"great\" + 0.022*\"fire\" + 0.016*\"product\" + 0.015*\"well\" + 0.014*\"use\" + 0.014*\"good\" + 0.013*\"need\" + 0.013*\"one\" + 0.012*\"buy\"'),\n",
       " (3,\n",
       "  '0.038*\"fire\" + 0.028*\"get\" + 0.026*\"use\" + 0.022*\"good\" + 0.021*\"start\" + 0.019*\"work\" + 0.019*\"spark\" + 0.013*\"one\" + 0.013*\"magnesium\" + 0.013*\"camp\"'),\n",
       " (4,\n",
       "  '0.030*\"magnesium\" + 0.026*\"use\" + 0.018*\"shave\" + 0.016*\"work\" + 0.015*\"fire\" + 0.012*\"get\" + 0.011*\"one\" + 0.010*\"striker\" + 0.010*\"flint\" + 0.009*\"make\"')]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_fire.print_topics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_normalize(lda_model, id2word, num):\n",
    "    dic_list = []\n",
    "    for i in range(num):\n",
    "        topic = lda_model.get_topic_terms(i,20)\n",
    "        dic = dict((x,y) for x,y in topic)\n",
    "        dic_list.append(dic)\n",
    "    df_topic = pd.DataFrame.from_records(dic_list)\n",
    "\n",
    "    words = []\n",
    "    for elem in df_topic.columns:\n",
    "        words.append(id2word.get(elem))\n",
    "    df_topic.columns = words\n",
    "\n",
    "    df_topic = df_topic.replace(np.nan, 0)\n",
    "    for elem in df_topic.columns:\n",
    "        df_topic[elem] = (df_topic[elem] - df_topic[elem].min()) / (df_topic[elem].max() - df_topic[elem].min())    \n",
    "    return df_topic\n",
    "\n",
    "df_topic_fire = create_df_normalize(lda_model_fire,id2word_fire ,5)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wir jetzt dem Dataframe 'df_topic_fire' nach der Spalte 'fire' schauen, wird nochmal deutlich der Effekt der Normalisierung. So ist bei Thema 4 und 2 die Gewichtung relativ hoch, während bei 0 und 1 das Wort anscheinend nicht so relevant ist im Vergleich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work</th>\n",
       "      <th>use</th>\n",
       "      <th>expect</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>advertise</th>\n",
       "      <th>fire</th>\n",
       "      <th>say</th>\n",
       "      <th>item</th>\n",
       "      <th>come</th>\n",
       "      <th>time</th>\n",
       "      <th>...</th>\n",
       "      <th>camp</th>\n",
       "      <th>bag</th>\n",
       "      <th>survival</th>\n",
       "      <th>take</th>\n",
       "      <th>little</th>\n",
       "      <th>easy</th>\n",
       "      <th>bar</th>\n",
       "      <th>lighter</th>\n",
       "      <th>better</th>\n",
       "      <th>strike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.264570</td>\n",
       "      <td>0.360490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.376135</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.843145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.724972</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.246325</td>\n",
       "      <td>0.961397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994462</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.174465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.982382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       work       use  expect  magnesium  advertise      fire  say      item  \\\n",
       "0  0.264570  0.360490     1.0   0.376135        1.0  0.000000  1.0  1.000000   \n",
       "1  0.000000  0.211949     0.0   1.000000        0.0  1.000000  0.0  0.000000   \n",
       "2  1.000000  0.000000     0.0   0.000000        0.0  0.386006  0.0  0.843145   \n",
       "3  0.246325  0.961397     0.0   0.415733        0.0  0.960042  0.0  0.000000   \n",
       "4  0.174465  1.000000     0.0   0.982382        0.0  0.135652  0.0  0.000000   \n",
       "\n",
       "   come      time  ...      camp  bag  survival  take  little  easy  bar  \\\n",
       "0   1.0  1.000000  ...  0.000000  0.0       0.0   0.0     0.0   0.0  0.0   \n",
       "1   0.0  0.000000  ...  0.000000  0.0       0.0   0.0     0.0   0.0  0.0   \n",
       "2   0.0  0.000000  ...  0.724972  1.0       1.0   0.0     0.0   0.0  0.0   \n",
       "3   0.0  0.994462  ...  1.000000  0.0       0.0   1.0     1.0   1.0  0.0   \n",
       "4   0.0  0.000000  ...  0.000000  0.0       0.0   0.0     0.0   0.0  1.0   \n",
       "\n",
       "   lighter  better  strike  \n",
       "0      0.0     0.0     0.0  \n",
       "1      0.0     0.0     0.0  \n",
       "2      0.0     0.0     0.0  \n",
       "3      0.0     0.0     0.0  \n",
       "4      1.0     1.0     1.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_fire"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt werden nochmal die Topics mit ihren Wörtern gedruckt, diesmal mit einer Schranke von 0.8.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thema  0 : Erwartungen zum Produkt\n",
      "expect       1.0\n",
      "advertise    1.0\n",
      "say          1.0\n",
      "item         1.0\n",
      "come         1.0\n",
      "time         1.0\n",
      "thank        1.0\n",
      "arrive       1.0\n",
      "yet          1.0\n",
      "much         1.0\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "Thema  1 : Beschreibung / Bedienung des Feuerstarters\n",
      "magnesium    1.000000\n",
      "fire         1.000000\n",
      "make         1.000000\n",
      "starter      1.000000\n",
      "light        1.000000\n",
      "like         1.000000\n",
      "spark        0.942575\n",
      "flint        0.930084\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "Thema  2 : Notfall-Item \n",
      "work         1.000000\n",
      "product      1.000000\n",
      "buy          1.000000\n",
      "need         1.000000\n",
      "would        1.000000\n",
      "great        1.000000\n",
      "well         1.000000\n",
      "price        1.000000\n",
      "emergency    1.000000\n",
      "kit          1.000000\n",
      "bag          1.000000\n",
      "survival     1.000000\n",
      "one          0.924966\n",
      "item         0.843145\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "Thema  3 : Kommentare bezüglich Camping\n",
      "one       1.000000\n",
      "go        1.000000\n",
      "spark     1.000000\n",
      "get       1.000000\n",
      "start     1.000000\n",
      "good      1.000000\n",
      "camp      1.000000\n",
      "take      1.000000\n",
      "little    1.000000\n",
      "easy      1.000000\n",
      "time      0.994462\n",
      "need      0.977910\n",
      "use       0.961397\n",
      "fire      0.960042\n",
      "Name: 3, dtype: float64\n",
      "\n",
      "Thema  4 : Bedienung des Feuerstarters\n",
      "use          1.000000\n",
      "striker      1.000000\n",
      "shave        1.000000\n",
      "flint        1.000000\n",
      "pile         1.000000\n",
      "bar          1.000000\n",
      "lighter      1.000000\n",
      "better       1.000000\n",
      "strike       1.000000\n",
      "light        0.988731\n",
      "magnesium    0.982382\n",
      "would        0.902459\n",
      "Name: 4, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_name = ['Erwartungen zum Produkt', 'Beschreibung / Bedienung des Feuerstarters', 'Notfall-Item ', 'Kommentare bezüglich Camping', 'Bedienung des Feuerstarters']\n",
    "for i in range(5):\n",
    "    print('Thema ',i,':',topic_name[i])\n",
    "    print(df_topic_fire.loc[df_topic_fire.index[i]].loc[lambda x : x > 0.8].sort_values(ascending = False))\n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MainTopic bestimmen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es soll wieder das Hauptthema bei jedem Text bestimmt werden, um eine spätere Analyse zu ermöglichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "maintopic(df_fire, lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transparent_histogram(df_fire)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Reviewtexte mit sehr niedrigen Werten beim Main Topic, werden erstmal entfernt, damit nur Texte mit starken Gewichtungen in die Analyse kommen. \n",
    "Die Grenze wird bei 0.5 gesetzt, sprich der Artikel soll zur Mehrheit zu einem Thema gehören."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     473\n",
       "0     475\n",
       "2     722\n",
       "4     808\n",
       "1    1152\n",
       "Name: maintopic, dtype: int64"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fire = df_fire[df_fire['mainscore'] > 0.5]\n",
    "df_fire['maintopic'].value_counts().sort_values()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thema 1 hat besonders viele zugeordnete Reviewtexte.\n",
    "Dies kann sich darauf zurückführen lassen, dass zum einen das Wort 'fire' mit 1 gewichtet ist und zum anderen es alles Wörter sind, welche den Artikel an sich beschreiben. Viele Reviews werden wahrscheinlich darüber schreiben, wie sie den Feuerstarter benutzt haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thema 1: Beschreibung / Bedienung des Feuerstarters\n",
      "magnesium    1.000000\n",
      "fire         1.000000\n",
      "make         1.000000\n",
      "starter      1.000000\n",
      "light        1.000000\n",
      "like         1.000000\n",
      "spark        0.942575\n",
      "flint        0.930084\n",
      "Name: 1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Thema 1: Beschreibung / Bedienung des Feuerstarters')\n",
    "print(df_topic_fire.loc[df_topic_fire.index[1]].loc[lambda x : x > 0.8].sort_values(ascending=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall und MainTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thema  0  hat eine durchschnittliche Bewertung von  4.434599156118144\n",
      "Thema  1  hat eine durchschnittliche Bewertung von  4.220767888307155\n",
      "Thema  2  hat eine durchschnittliche Bewertung von  4.254495159059474\n",
      "Thema  3  hat eine durchschnittliche Bewertung von  4.408898305084746\n",
      "Thema  4  hat eine durchschnittliche Bewertung von  3.7460122699386504\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    avg = df_fire.loc[df_fire['maintopic'] == i, 'overall'].mean()\n",
    "    print('Thema ',i, ' hat eine durchschnittliche Bewertung von ', avg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In den Durchschnittswerten von 'overall' ist auffällig, dass Thema 4 im Vergleich niedrigere Bewertungen erhalten haben. Um eine genauere Aufteilung zu sehen, werden die Anzahl an 1* und 5* Reviews mit der Gesamtzahl an Reviews in diesen Topic verglichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thema  0\n",
      "Anteil von 1*:  2.32 %\n",
      "Anteil von 5*:  64.0 %\n",
      "Thema  1\n",
      "Anteil von 1*:  6.86 %\n",
      "Anteil von 5*:  59.64 %\n",
      "Thema  2\n",
      "Anteil von 1*:  6.37 %\n",
      "Anteil von 5*:  63.71 %\n",
      "Thema  3\n",
      "Anteil von 1*:  3.59 %\n",
      "Anteil von 5*:  68.5 %\n",
      "Thema  4\n",
      "Anteil von 1*:  11.14 %\n",
      "Anteil von 5*:  39.6 %\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('Thema ',i)\n",
    "    counts = df_fire.loc[df_fire['maintopic'] == i, 'overall'].value_counts()\n",
    "    low = counts[1]/counts.sum()\n",
    "    high = counts[5]/counts.sum()\n",
    "    # print(df_fire.loc[df_fire['maintopic'] == i, 'overall'].value_counts().sum())\n",
    "    print('Anteil von 1*: ',round(low*100, 2),'%')\n",
    "    print('Anteil von 5*: ',round(high*100,2),'%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird deutlich, dass Thema 4 besonders viele schlechte Bewertungen erhalten hat mit 11.14% und nur 39.6% mit sehr guter Bewertung.\n",
    "Im Vergleich dazu haben Thema 0 und 3 sehr viele gute Bewertungen und relativ wenige schlechte.\n",
    "\n",
    "In den nächsten Teil soll Thema 4 näher betrachtet werden um vielleicht den Grund für die Bewertungen zu finden.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thema 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad Reviews\n",
      "Text  0 : cheap imitation doesnt spark at all with the striker hardly sparks even with a sharp knife  the magnesium block is too thick and flint is too thin often preventing a good strike of the flint (Rating  1 )\n",
      "Text  1 : broke and 'magnesium' was aluminum and would not light even with torch lighter rod fell off after 3 strikes (Rating  1 )\n",
      "Text  2 : i bought this for a survival bag and wanted to try it lighting a fire in my fire pit it never did ignite when i made a pile of shavings and put sparks on the pile don't know if it even is magnesium as magnesium is highly flammable (Rating  1 )\n",
      "\n",
      " Good Reviews\n",
      "Text  0 : gets the job done  glad to have it (Rating  5 )\n",
      "Text  1 : i love how compact this little tool is and that it actually does a good job of sparking some tinder so i can get my fire going  5 gold stars ;) (Rating  5 )\n",
      "Text  2 : grandson loves it (Rating  5 )\n"
     ]
    }
   ],
   "source": [
    "df_fire_topic_4 = df_fire.loc[(df_fire['maintopic'] == 4)]\n",
    "df_fire_topic_4_bad = df_fire_topic_4.loc[(df_fire['overall'] == 1)]\n",
    "print('Bad Reviews')\n",
    "for i in range(3):\n",
    "    print('Text ',i,':', df_fire_topic_4_bad.iloc[i]['reviewText'], '(Rating ', df_fire_topic_4_bad.iloc[i]['overall'],')')\n",
    "print('\\n Good Reviews')\n",
    "df_fire_topic_4_good = df_fire_topic_4.loc[(df_fire['overall'] == 5)]\n",
    "for i in range(3):\n",
    "    print('Text ',i,':', df_fire_topic_4_good.iloc[i]['reviewText'], '(Rating ', df_fire_topic_4_good.iloc[i]['overall'],')')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die negativen Reviews beschreiben, wie der Feuerstarter nicht funktioniert hat und begründen es mit einer Beschreibung des Artikels.\n",
    "Die positiven Reviews beschreiben, wie der Feuerstarter doch funktioniert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "overall_4 = df_fire_topic_4['overall'].value_counts()\n",
    "x = overall_4.index\n",
    "y = overall_4.values\n",
    "\n",
    "plt.bar(x, y)\n",
    "plt.show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Verteilung der Werte von 'overall' ist erkennbar, dass trotz der schlechteren Durchschnittsbewertung, die meisten eine 5* Bewertung da gelassen haben.\n",
    "Dennoch ist auch sichtbar, dass das Mittelfeld stark vertreten ist und es sogar mehr 1* als 2* Bewertungen gibt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein weiterer Teil der geprüft werden kann, ist welche Adjektive genutzt wurden innerhalb eines Reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', 280),\n",
       " ('one', 165),\n",
       " ('little', 160),\n",
       " ('like', 130),\n",
       " ('would', 124),\n",
       " ('well', 123),\n",
       " ('great', 112),\n",
       " ('small', 106),\n",
       " ('nice', 96),\n",
       " ('even', 90)]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_4_adjectives = []\n",
    "\n",
    "def get_adjectives_in_list(elem):\n",
    "    topic_4_adjectives.extend(elem)\n",
    "\n",
    "df_fire_topic_4['adjectives'].apply(get_adjectives_in_list)\n",
    "\n",
    "Counter(topic_4_adjectives).most_common(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etwas was nicht erkennbar ist aus dieser Analyse, ist ob das Adjektiv direkt oder verneint benutzt wurde. Deswegen ist es schwierig ein direktes Sentiment daraus zu erkennen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDAMulticore - Substantive"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuletzt wird ein kurzer Blick in die Substantive der Reviews geworfen in der Hoffnung deutlichere Topics zu sehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fire_sub = df_fire.nouns.values.tolist()\n",
    "id2word_fire_sub = corpora.Dictionary(data_fire_sub)\n",
    "corpus_fire_sub = [id2word_fire_sub.doc2bow(elem) for elem in data_fire_sub]\n",
    "lda_model_fire_sub = gensim.models.LdaMulticore(corpus=corpus_fire_sub, id2word=id2word_fire_sub, num_topics=5, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . Reviewtext:  ['fire', 'starter', 'work', 'instructions', 'day', 'fire', 'time']\n",
      "Thema  0 :  1.8463190644979477 %\n",
      "Thema  1 :  75.98649859428406 %\n",
      "Thema  2 :  1.841898262500763 %\n",
      "Thema  3 :  18.482783436775208 %\n",
      "Thema  4 :  1.8424993380904198 %\n",
      "\n",
      "2 . Reviewtext:  ['promise', 'bug', 'bag']\n",
      "Thema  0 :  4.005338624119759 %\n",
      "Thema  1 :  24.118690192699432 %\n",
      "Thema  2 :  63.87256979942322 %\n",
      "Thema  3 :  4.000882804393768 %\n",
      "Thema  4 :  4.002519324421883 %\n",
      "\n",
      "3 . Reviewtext:  ['work', 'thats', 'thing', 'hand', 'pocket', 'everything', 'fire', 'thats', 'end', 'afford', 'pay', 'option', 'work']\n",
      "Thema  0 :  8.797509968280792 %\n",
      "Thema  1 :  36.55913770198822 %\n",
      "Thema  3 :  19.539928436279297 %\n",
      "Thema  4 :  34.26147997379303 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    bow_sub = id2word_fire_sub.doc2bow(df_fire.iloc[i]['reviewText_tokenize'])\n",
    "    docu_topics_sub = lda_model_fire_sub.get_document_topics(bow_sub)\n",
    "\n",
    "    print(i+1,'. Reviewtext: ', df_fire.iloc[i]['nouns'])\n",
    "    for top in docu_topics_sub:\n",
    "        print('Thema ',top[0],': ', top[1]*100,'%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work</th>\n",
       "      <th>practice</th>\n",
       "      <th>lot</th>\n",
       "      <th>fire</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>use</th>\n",
       "      <th>time</th>\n",
       "      <th>start</th>\n",
       "      <th>junk</th>\n",
       "      <th>buy</th>\n",
       "      <th>...</th>\n",
       "      <th>scrape</th>\n",
       "      <th>pile</th>\n",
       "      <th>link</th>\n",
       "      <th>striker</th>\n",
       "      <th>knife</th>\n",
       "      <th>chain</th>\n",
       "      <th>thing</th>\n",
       "      <th>tinder</th>\n",
       "      <th>blade</th>\n",
       "      <th>piece</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624003</td>\n",
       "      <td>0.526477</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.160222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.539678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.537900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.035575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.593169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940853</td>\n",
       "      <td>0.346735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.628099</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.504446</td>\n",
       "      <td>0.990441</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.574127</td>\n",
       "      <td>0.929168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       work  practice  lot      fire  magnesium       use      time     start  \\\n",
       "0  0.054190       1.0  1.0  0.000000   0.262251  0.000000  0.624003  0.526477   \n",
       "1  1.000000       0.0  0.0  1.000000   0.000000  0.148148  1.000000  1.000000   \n",
       "2  0.160222       0.0  0.0  0.238714   0.000000  0.539678  0.000000  0.537900   \n",
       "3  0.035575       0.0  0.0  0.593169   1.000000  0.940853  0.346735  0.000000   \n",
       "4  0.000000       0.0  0.0  0.504446   0.990441  1.000000  0.574127  0.929168   \n",
       "\n",
       "   junk       buy  ...  scrape  pile  link  striker  knife  chain  thing  \\\n",
       "0   1.0  1.000000  ...     0.0   0.0   0.0      0.0    0.0    0.0    0.0   \n",
       "1   0.0  0.000000  ...     0.0   0.0   0.0      0.0    0.0    0.0    0.0   \n",
       "2   0.0  0.000000  ...     0.0   0.0   0.0      0.0    0.0    0.0    0.0   \n",
       "3   0.0  0.628099  ...     1.0   1.0   1.0      0.0    0.0    0.0    0.0   \n",
       "4   0.0  0.000000  ...     0.0   0.0   0.0      1.0    1.0    1.0    1.0   \n",
       "\n",
       "   tinder  blade  piece  \n",
       "0     0.0    0.0    0.0  \n",
       "1     0.0    0.0    0.0  \n",
       "2     0.0    0.0    0.0  \n",
       "3     0.0    0.0    0.0  \n",
       "4     1.0    1.0    1.0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_fire_sub = create_df_normalize(lda_model_fire_sub,id2word_fire_sub ,5)\n",
    "df_topic_fire_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thema  0 : Bewertung\n",
      "practice       1.0\n",
      "lot            1.0\n",
      "junk           1.0\n",
      "buy            1.0\n",
      "job            1.0\n",
      "gift           1.0\n",
      "love           1.0\n",
      "mag            1.0\n",
      "box            1.0\n",
      "emergencies    1.0\n",
      "stick          1.0\n",
      "scout          1.0\n",
      "Name: 0, dtype: float64 2\n",
      "\n",
      "Thema  1 : Beschreibung / Bedienung des Feuerstarters\n",
      "work         1.0\n",
      "fire         1.0\n",
      "time         1.0\n",
      "start        1.0\n",
      "product      1.0\n",
      "price        1.0\n",
      "item         1.0\n",
      "starter      1.0\n",
      "pack         1.0\n",
      "quality      1.0\n",
      "need         1.0\n",
      "advertise    1.0\n",
      "describe     1.0\n",
      "order        1.0\n",
      "ship         1.0\n",
      "something    1.0\n",
      "Name: 1, dtype: float64 2\n",
      "\n",
      "Thema  2 : Camping\n",
      "match        1.0\n",
      "camp         1.0\n",
      "try          1.0\n",
      "emergency    1.0\n",
      "bag          1.0\n",
      "kit          1.0\n",
      "purchase     1.0\n",
      "tool         1.0\n",
      "bug          1.0\n",
      "backpack     1.0\n",
      "case         1.0\n",
      "addition     1.0\n",
      "trip         1.0\n",
      "Name: 2, dtype: float64 2\n",
      "\n",
      "Thema  3 : Beschreibung / Bedienung des Feuerstarters\n",
      "magnesium    1.0\n",
      "bar          1.0\n",
      "size         1.0\n",
      "starters     1.0\n",
      "rod          1.0\n",
      "scrape       1.0\n",
      "pile         1.0\n",
      "link         1.0\n",
      "use          1.0\n",
      "starter      1.0\n",
      "strike       1.0\n",
      "Name: 3, dtype: float64 2\n",
      "\n",
      "Thema  4 : Beschreibung / Bedienung des Feuerstarters\n",
      "use          1.0\n",
      "spark        1.0\n",
      "strike       1.0\n",
      "flint        1.0\n",
      "get          1.0\n",
      "striker      1.0\n",
      "knife        1.0\n",
      "chain        1.0\n",
      "thing        1.0\n",
      "tinder       1.0\n",
      "blade        1.0\n",
      "piece        1.0\n",
      "magnesium    1.0\n",
      "start        1.0\n",
      "rod          1.0\n",
      "Name: 4, dtype: float64 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_name_2 = ['Bewertung','Beschreibung / Bedienung des Feuerstarters','Camping','Beschreibung / Bedienung des Feuerstarters','Beschreibung / Bedienung des Feuerstarters']\n",
    "for i in range(5):\n",
    "    print('Thema ',i,':',topic_name_2[i])\n",
    "    print(round(df_topic_fire_sub.loc[df_topic_fire_sub.index[i]].loc[lambda x : x > 0.8].sort_values(ascending = False)),2)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch hier ist es wieder schwierig, konkrete Namen oder Beschreibungen für die Themen zu finden. Was ebenfalls auffällt ist, dass manche Wörter bei verschiedenen Themen eine Gewichtung von 1 haben. Der ursprüngliche Wert muss in diesen Fällen identisch gewesen sein."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27ae24611313c19d960451cdb05df3bc295904b3a78b9619ab6ba5f9d097378a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
